{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ir_datasets\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 ir_datasets 来加载并下载 clirmatrix Bi139 数据\n",
    "# `ir_datasets.load('clirmatrix/{doc_lang}/{bi139-base|bi139-full}/{query_lang}/{train|dev|test1|test2}')`\n",
    "# eg：`ir_datasets.load('clirmatrix/kk/bi139-full/zh/train')`\n",
    "\n",
    "# dataset1 = ir_datasets.load('clirmatrix/kk/bi139-full/zh/train')\n",
    "dataset2 = ir_datasets.load('clirmatrix/kk/bi139-full/zh/test1')\n",
    "dataset3 = ir_datasets.load('clirmatrix/kk/bi139-full/zh/test2')\n",
    "# dataset4 = ir_datasets.load('clirmatrix/kk/bi139-full/zh/dev')\n",
    "\n",
    "# dataset1 = ir_datasets.load('clirmatrix/zh/bi139-full/kk/train')\n",
    "# dataset2 = ir_datasets.load('clirmatrix/zh/bi139-full/kk/test1')\n",
    "# dataset3 = ir_datasets.load('clirmatrix/zh/bi139-full/kk/test2')\n",
    "# dataset4 = ir_datasets.load('clirmatrix/zh/bi139-full/kk/dev')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230047"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset3.docs_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] If you have a local copy of http://www.cs.jhu.edu/~shuosun/clirmatrix/data/BI-139/full/kk/kk.zh.test2.jl.gz, you can symlink it here to avoid downloading it again: C:\\Users\\yanghe\\.ir_datasets\\downloads\\29dffe9fbbced53ce484f921de65e445\n",
      "[INFO] [starting] http://www.cs.jhu.edu/~shuosun/clirmatrix/data/BI-139/full/kk/kk.zh.test2.jl.gz\n",
      "[INFO] [finished] http://www.cs.jhu.edu/~shuosun/clirmatrix/data/BI-139/full/kk/kk.zh.test2.jl.gz: [00:00] [1.55MB] [2.48MB/s]\n",
      "[INFO] If you have a local copy of http://www.cs.jhu.edu/~shuosun/clirmatrix/data/BI-139/full/kk/kk.zh.dev.jl.gz, you can symlink it here to avoid downloading it again: C:\\Users\\yanghe\\.ir_datasets\\downloads\\38a275193f557ceba0d748b2587409a4\n",
      "[INFO] [starting] http://www.cs.jhu.edu/~shuosun/clirmatrix/data/BI-139/full/kk/kk.zh.dev.jl.gz\n",
      "[INFO] [finished] http://www.cs.jhu.edu/~shuosun/clirmatrix/data/BI-139/full/kk/kk.zh.dev.jl.gz: [00:00] [1.55MB] [3.19MB/s]\n",
      "                                                                                                          \r"
     ]
    }
   ],
   "source": [
    "# docstore = dataset.docs_store()\n",
    "# queries_df = pd.DataFrame(dataset.queries_iter())\n",
    "# qrels_df = pd.DataFrame(dataset.qrels_iter())\n",
    "# docstore1 = dataset1.docs_store()\n",
    "queries_df1 = pd.DataFrame(dataset1.queries_iter())\n",
    "# qrels_df1 = pd.DataFrame(dataset1.qrels_iter())\n",
    "\n",
    "\n",
    "# docstore2 = dataset2.docs_store()\n",
    "queries_df2 = pd.DataFrame(dataset2.queries_iter())\n",
    "# qrels_df2 = pd.DataFrame(dataset2.qrels_iter())\n",
    "\n",
    "queries_df3 = pd.DataFrame(dataset3.queries_iter())\n",
    "# qrels_df3 = pd.DataFrame(dataset3.qrels_iter())\n",
    "\n",
    "queries_df4 = pd.DataFrame(dataset4.queries_iter())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18603"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries_df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131395"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_qid = qrels_df1.groupby('query_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_qid1 = grouped_qid.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239934"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grouped_qid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3149545"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qrels_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131395"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grouped_qid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82102"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_home = Path.home() / \"Desktop\" / \"Datasets\" / \"CLIRMatrix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>计算机科学</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74</td>\n",
       "      <td>化學</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76</td>\n",
       "      <td>地理学</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159</td>\n",
       "      <td>植物学</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>211</td>\n",
       "      <td>语言列表</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82097</th>\n",
       "      <td>6862433</td>\n",
       "      <td>國際籃聯歐洲盃</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82098</th>\n",
       "      <td>6862443</td>\n",
       "      <td>原田孝一</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82099</th>\n",
       "      <td>6862548</td>\n",
       "      <td>上海惠灵顿外籍人员子女学校</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82100</th>\n",
       "      <td>6862678</td>\n",
       "      <td>梅米·贝西诺维奇</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82101</th>\n",
       "      <td>6862740</td>\n",
       "      <td>杜克·史奈德</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82102 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      query_id           text\n",
       "0           25          计算机科学\n",
       "1           74             化學\n",
       "2           76            地理学\n",
       "3          159            植物学\n",
       "4          211           语言列表\n",
       "...        ...            ...\n",
       "82097  6862433        國際籃聯歐洲盃\n",
       "82098  6862443           原田孝一\n",
       "82099  6862548  上海惠灵顿外籍人员子女学校\n",
       "82100  6862678       梅米·贝西诺维奇\n",
       "82101  6862740         杜克·史奈德\n",
       "\n",
       "[82102 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每 10000 条数据 存储为一个 xlsx 然后使用 yandex translate 翻译这个 xlsx 文件\n",
    "# queries_df2.loc[80000:89999].to_excel(str(path_home / 'queries_zh.kk_80000_89999.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 文件夹路径\n",
    "folder_path = str(path_home / 'BI-139' / 'queries_test1_zh_kk')\n",
    "# 存储合并后数据的DataFrame\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# 遍历文件夹中的文件\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.xlsx') and 'queries' in filename:\n",
    "        # 构建完整的文件路径\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # 读取Excel文件，只选取'query_id'和'text'两列\n",
    "        temp_df = pd.read_excel(file_path, usecols=['query_id', 'text'])\n",
    "        \n",
    "#         # 将读取的数据追加到all_data DataFrame中\n",
    "#         all_data = pd.concat([all_data, temp_df], ignore_index=True)\n",
    "\n",
    "# # 将'query_id'和'text'列转换为字符串类型\n",
    "# all_data[['query_id', 'text']] = all_data[['query_id', 'text']].astype(str)\n",
    "\n",
    "# # 保存到新的Excel文件\n",
    "# all_data.to_excel('queries_zh.kk.xlsx', index=False)\n",
    "\n",
    "# print(\"合并并转换完成，结果已保存至queries_zh.kk.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 示例数据\n",
    "# data = [\n",
    "#     {\"query_id\": 25, \"text\": \"计算机科学\"},\n",
    "#     {\"query_id\": 74, \"text\": \"化学\"},\n",
    "#     {\"query_id\": 76, \"text\": \"2023年\"}, # 应该被过滤\n",
    "#     {\"query_id\": 543, \"text\": \"2023年后\"},  \n",
    "#     {\"query_id\": 159, \"text\": \"植物学\"},\n",
    "#     {\"query_id\": 211, \"text\": \"12345\"},  # 应该被过滤\n",
    "#     # ... 更多数据\n",
    "# ]\n",
    "\n",
    "# data_df = pd.DataFrame(data)\n",
    "# # 去除 数字和xx年的查询\n",
    "# data_df = data_df[~data_df['text'].str.match(r'^\\d+$|.*年$')]\n",
    "# print(data_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

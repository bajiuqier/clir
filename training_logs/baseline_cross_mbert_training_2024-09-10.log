2024-09-10 18:56:16 [INFO]   ***** Running training *****
2024-09-10 18:56:16 [INFO]   当前时间: 2024-09-10 18:56:16
2024-09-10 18:56:16 [INFO]   Num examples = 5087
2024-09-10 18:56:16 [INFO]   Num Epochs = 12
2024-09-10 18:56:16 [INFO]   Instantaneous batch size per device = 16
2024-09-10 18:56:16 [INFO]   Total train batch size (w. parallel, distributed & accumulation) = 32
2024-09-10 18:56:16 [INFO]   Total optimization steps = 3804
2024-09-10 18:56:16 [INFO]   训练的设备: cuda, 设备编号: 0
2024-09-10 18:56:23 [INFO]   loss: 0.5536,	steps: 10/3804,	epoch: 0,	learning_rate: 3.1545741324921137e-07
2024-09-10 18:56:28 [INFO]   loss: 0.5296,	steps: 20/3804,	epoch: 0,	learning_rate: 6.309148264984227e-07
2024-09-10 18:56:33 [INFO]   loss: 0.5197,	steps: 30/3804,	epoch: 0,	learning_rate: 9.463722397476341e-07
2024-09-10 18:56:37 [INFO]   loss: 0.4889,	steps: 40/3804,	epoch: 0,	learning_rate: 1.2618296529968455e-06
2024-09-10 18:56:42 [INFO]   loss: 0.4995,	steps: 50/3804,	epoch: 0,	learning_rate: 1.5772870662460567e-06
2024-09-10 18:56:47 [INFO]   loss: 0.5167,	steps: 60/3804,	epoch: 0,	learning_rate: 1.8927444794952682e-06
2024-09-10 18:56:52 [INFO]   loss: 0.4891,	steps: 70/3804,	epoch: 0,	learning_rate: 2.2082018927444797e-06
2024-09-10 18:56:57 [INFO]   loss: 0.4930,	steps: 80/3804,	epoch: 0,	learning_rate: 2.523659305993691e-06
2024-09-10 18:57:01 [INFO]   loss: 0.4629,	steps: 90/3804,	epoch: 0,	learning_rate: 2.8391167192429026e-06
2024-09-10 18:57:06 [INFO]   loss: 0.4741,	steps: 100/3804,	epoch: 0,	learning_rate: 3.1545741324921135e-06
2024-09-10 18:57:11 [INFO]   loss: 0.4199,	steps: 110/3804,	epoch: 0,	learning_rate: 3.470031545741325e-06
2024-09-10 18:57:16 [INFO]   loss: 0.3670,	steps: 120/3804,	epoch: 0,	learning_rate: 3.7854889589905364e-06
2024-09-10 18:57:21 [INFO]   loss: 0.3049,	steps: 130/3804,	epoch: 0,	learning_rate: 4.100946372239748e-06
2024-09-10 18:57:26 [INFO]   loss: 0.2929,	steps: 140/3804,	epoch: 0,	learning_rate: 4.416403785488959e-06
2024-09-10 18:57:31 [INFO]   loss: 0.3300,	steps: 150/3804,	epoch: 0,	learning_rate: 4.731861198738171e-06
2024-09-10 18:57:35 [INFO]   loss: 0.2773,	steps: 160/3804,	epoch: 0,	learning_rate: 5.047318611987382e-06
2024-09-10 18:57:40 [INFO]   loss: 0.2222,	steps: 170/3804,	epoch: 0,	learning_rate: 5.3627760252365935e-06
2024-09-10 18:57:45 [INFO]   loss: 0.3290,	steps: 180/3804,	epoch: 0,	learning_rate: 5.678233438485805e-06
2024-09-10 18:57:50 [INFO]   loss: 0.2034,	steps: 190/3804,	epoch: 0,	learning_rate: 5.993690851735017e-06
2024-09-10 18:57:55 [INFO]   loss: 0.1993,	steps: 200/3804,	epoch: 0,	learning_rate: 6.309148264984227e-06
2024-09-10 18:58:00 [INFO]   loss: 0.2482,	steps: 210/3804,	epoch: 0,	learning_rate: 6.624605678233439e-06
2024-09-10 18:58:05 [INFO]   loss: 0.2836,	steps: 220/3804,	epoch: 0,	learning_rate: 6.94006309148265e-06
2024-09-10 18:58:10 [INFO]   loss: 0.1702,	steps: 230/3804,	epoch: 0,	learning_rate: 7.255520504731862e-06
2024-09-10 18:58:15 [INFO]   loss: 0.2119,	steps: 240/3804,	epoch: 0,	learning_rate: 7.570977917981073e-06
2024-09-10 18:58:19 [INFO]   loss: 0.2141,	steps: 250/3804,	epoch: 0,	learning_rate: 7.886435331230284e-06
2024-09-10 18:58:24 [INFO]   loss: 0.0920,	steps: 260/3804,	epoch: 0,	learning_rate: 8.201892744479495e-06
2024-09-10 18:58:29 [INFO]   loss: 0.0489,	steps: 270/3804,	epoch: 0,	learning_rate: 8.517350157728708e-06
2024-09-10 18:58:34 [INFO]   loss: 0.0737,	steps: 280/3804,	epoch: 0,	learning_rate: 8.832807570977919e-06
2024-09-10 18:58:39 [INFO]   loss: 0.1455,	steps: 290/3804,	epoch: 0,	learning_rate: 9.14826498422713e-06
2024-09-10 18:58:44 [INFO]   loss: 0.0146,	steps: 300/3804,	epoch: 0,	learning_rate: 9.463722397476342e-06
2024-09-10 18:58:49 [INFO]   loss: 0.1153,	steps: 310/3804,	epoch: 0,	learning_rate: 9.779179810725553e-06
2024-09-10 19:09:42 [INFO]   第0轮的训练 测试结果为：{'R@5': 0.44937289919111256, 'R@10': 0.6158818621459862, 'RR@5': 0.7660539215686281, 'RR@10': 0.7727000175070033, 'nDCG@5': 0.5404226002029162, 'nDCG@10': 0.5936264313175633}
2024-09-10 19:09:43 [INFO]   ------------------------------------------------
2024-09-10 19:09:43 [INFO]   第 0 轮已经训练完成  模型保存在 /mnt/workspace/clir/baselines/cross-mbert/output/best_model
2024-09-10 19:09:43 [INFO]   ------------------------------------------------
2024-09-10 19:09:44 [INFO]   loss: 0.0563,	steps: 320/3804,	epoch: 1,	learning_rate: 9.991396616002295e-06
2024-09-10 19:09:49 [INFO]   loss: 0.1655,	steps: 330/3804,	epoch: 1,	learning_rate: 9.962718669343275e-06
2024-09-10 19:09:54 [INFO]   loss: 0.1723,	steps: 340/3804,	epoch: 1,	learning_rate: 9.934040722684256e-06
2024-09-10 19:09:59 [INFO]   loss: 0.1624,	steps: 350/3804,	epoch: 1,	learning_rate: 9.905362776025236e-06
2024-09-10 19:10:04 [INFO]   loss: 0.0842,	steps: 360/3804,	epoch: 1,	learning_rate: 9.876684829366218e-06
2024-09-10 19:10:09 [INFO]   loss: 0.0930,	steps: 370/3804,	epoch: 1,	learning_rate: 9.8480068827072e-06
2024-09-10 19:10:14 [INFO]   loss: 0.1524,	steps: 380/3804,	epoch: 1,	learning_rate: 9.819328936048181e-06
2024-09-10 19:10:19 [INFO]   loss: 0.0143,	steps: 390/3804,	epoch: 1,	learning_rate: 9.790650989389161e-06
2024-09-10 19:10:24 [INFO]   loss: 0.0254,	steps: 400/3804,	epoch: 1,	learning_rate: 9.761973042730143e-06
2024-09-10 19:10:29 [INFO]   loss: 0.1540,	steps: 410/3804,	epoch: 1,	learning_rate: 9.733295096071122e-06
2024-09-10 19:10:34 [INFO]   loss: 0.0609,	steps: 420/3804,	epoch: 1,	learning_rate: 9.704617149412104e-06
2024-09-10 19:10:39 [INFO]   loss: 0.1269,	steps: 430/3804,	epoch: 1,	learning_rate: 9.675939202753084e-06
2024-09-10 19:10:44 [INFO]   loss: 0.0596,	steps: 440/3804,	epoch: 1,	learning_rate: 9.647261256094066e-06
2024-09-10 19:10:49 [INFO]   loss: 0.0845,	steps: 450/3804,	epoch: 1,	learning_rate: 9.618583309435045e-06
2024-09-10 19:10:54 [INFO]   loss: 0.1941,	steps: 460/3804,	epoch: 1,	learning_rate: 9.589905362776027e-06
2024-09-10 19:10:59 [INFO]   loss: 0.0868,	steps: 470/3804,	epoch: 1,	learning_rate: 9.561227416117007e-06
2024-09-10 19:11:04 [INFO]   loss: 0.0918,	steps: 480/3804,	epoch: 1,	learning_rate: 9.532549469457989e-06
2024-09-10 19:11:09 [INFO]   loss: 0.0458,	steps: 490/3804,	epoch: 1,	learning_rate: 9.503871522798968e-06
2024-09-10 19:11:13 [INFO]   loss: 0.1076,	steps: 500/3804,	epoch: 1,	learning_rate: 9.47519357613995e-06
2024-09-10 19:11:18 [INFO]   loss: 0.0111,	steps: 510/3804,	epoch: 1,	learning_rate: 9.44651562948093e-06
2024-09-10 19:11:23 [INFO]   loss: 0.1713,	steps: 520/3804,	epoch: 1,	learning_rate: 9.417837682821912e-06
2024-09-10 19:11:28 [INFO]   loss: 0.1665,	steps: 530/3804,	epoch: 1,	learning_rate: 9.389159736162892e-06
2024-09-10 19:11:33 [INFO]   loss: 0.0859,	steps: 540/3804,	epoch: 1,	learning_rate: 9.360481789503873e-06
2024-09-10 19:11:38 [INFO]   loss: 0.0380,	steps: 550/3804,	epoch: 1,	learning_rate: 9.331803842844853e-06
2024-09-10 19:11:43 [INFO]   loss: 0.0526,	steps: 560/3804,	epoch: 1,	learning_rate: 9.303125896185835e-06
2024-09-10 19:11:48 [INFO]   loss: 0.1488,	steps: 570/3804,	epoch: 1,	learning_rate: 9.274447949526815e-06
2024-09-10 19:11:53 [INFO]   loss: 0.0430,	steps: 580/3804,	epoch: 1,	learning_rate: 9.245770002867796e-06
2024-09-10 19:11:58 [INFO]   loss: 0.0968,	steps: 590/3804,	epoch: 1,	learning_rate: 9.217092056208776e-06
2024-09-10 19:12:03 [INFO]   loss: 0.0588,	steps: 600/3804,	epoch: 1,	learning_rate: 9.188414109549758e-06
2024-09-10 19:12:08 [INFO]   loss: 0.0142,	steps: 610/3804,	epoch: 1,	learning_rate: 9.159736162890738e-06
2024-09-10 19:12:12 [INFO]   loss: 0.0181,	steps: 620/3804,	epoch: 1,	learning_rate: 9.13105821623172e-06
2024-09-10 19:12:17 [INFO]   loss: 0.1505,	steps: 630/3804,	epoch: 1,	learning_rate: 9.102380269572699e-06
2024-09-10 19:23:05 [INFO]   第1轮的训练 测试结果为：{'R@5': 0.4970702604566539, 'R@10': 0.6671900410063346, 'RR@5': 0.8178308823529417, 'RR@10': 0.8227645745798323, 'nDCG@5': 0.6037621247649776, 'nDCG@10': 0.6540870306156646}
2024-09-10 19:23:08 [INFO]   ------------------------------------------------
2024-09-10 19:23:08 [INFO]   第 1 轮已经训练完成  模型保存在 /mnt/workspace/clir/baselines/cross-mbert/output/best_model
2024-09-10 19:23:08 [INFO]   ------------------------------------------------
2024-09-10 19:23:11 [INFO]   loss: 0.1060,	steps: 640/3804,	epoch: 2,	learning_rate: 9.07370232291368e-06
2024-09-10 19:23:16 [INFO]   loss: 0.0300,	steps: 650/3804,	epoch: 2,	learning_rate: 9.04502437625466e-06
2024-09-10 19:23:21 [INFO]   loss: 0.0954,	steps: 660/3804,	epoch: 2,	learning_rate: 9.016346429595642e-06
2024-09-10 19:23:26 [INFO]   loss: 0.0819,	steps: 670/3804,	epoch: 2,	learning_rate: 8.987668482936622e-06
2024-09-10 19:23:31 [INFO]   loss: 0.0357,	steps: 680/3804,	epoch: 2,	learning_rate: 8.958990536277604e-06
2024-09-10 19:23:36 [INFO]   loss: 0.0471,	steps: 690/3804,	epoch: 2,	learning_rate: 8.930312589618584e-06
2024-09-10 19:23:40 [INFO]   loss: 0.0796,	steps: 700/3804,	epoch: 2,	learning_rate: 8.901634642959565e-06
2024-09-10 19:23:45 [INFO]   loss: 0.0372,	steps: 710/3804,	epoch: 2,	learning_rate: 8.872956696300545e-06
2024-09-10 19:23:50 [INFO]   loss: 0.0658,	steps: 720/3804,	epoch: 2,	learning_rate: 8.844278749641527e-06
2024-09-10 19:23:55 [INFO]   loss: 0.0077,	steps: 730/3804,	epoch: 2,	learning_rate: 8.815600802982507e-06
2024-09-10 19:24:00 [INFO]   loss: 0.0445,	steps: 740/3804,	epoch: 2,	learning_rate: 8.786922856323488e-06
2024-09-10 19:24:05 [INFO]   loss: 0.0132,	steps: 750/3804,	epoch: 2,	learning_rate: 8.758244909664468e-06
2024-09-10 19:24:10 [INFO]   loss: 0.1322,	steps: 760/3804,	epoch: 2,	learning_rate: 8.72956696300545e-06
2024-09-10 19:24:15 [INFO]   loss: 0.0464,	steps: 770/3804,	epoch: 2,	learning_rate: 8.70088901634643e-06
2024-09-10 19:24:20 [INFO]   loss: 0.0205,	steps: 780/3804,	epoch: 2,	learning_rate: 8.672211069687411e-06
2024-09-10 19:24:25 [INFO]   loss: 0.0113,	steps: 790/3804,	epoch: 2,	learning_rate: 8.643533123028391e-06
2024-09-10 19:24:30 [INFO]   loss: 0.0677,	steps: 800/3804,	epoch: 2,	learning_rate: 8.614855176369373e-06
2024-09-10 19:24:35 [INFO]   loss: 0.0360,	steps: 810/3804,	epoch: 2,	learning_rate: 8.586177229710353e-06
2024-09-10 19:24:40 [INFO]   loss: 0.0097,	steps: 820/3804,	epoch: 2,	learning_rate: 8.557499283051334e-06
2024-09-10 19:24:45 [INFO]   loss: 0.0415,	steps: 830/3804,	epoch: 2,	learning_rate: 8.528821336392314e-06
2024-09-10 19:24:50 [INFO]   loss: 0.0020,	steps: 840/3804,	epoch: 2,	learning_rate: 8.500143389733296e-06
2024-09-10 19:24:55 [INFO]   loss: 0.0159,	steps: 850/3804,	epoch: 2,	learning_rate: 8.471465443074277e-06
2024-09-10 19:25:00 [INFO]   loss: 0.0061,	steps: 860/3804,	epoch: 2,	learning_rate: 8.442787496415257e-06
2024-09-10 19:25:05 [INFO]   loss: 0.0062,	steps: 870/3804,	epoch: 2,	learning_rate: 8.414109549756239e-06
2024-09-10 19:25:09 [INFO]   loss: 0.0223,	steps: 880/3804,	epoch: 2,	learning_rate: 8.385431603097219e-06
2024-09-10 19:25:14 [INFO]   loss: 0.0150,	steps: 890/3804,	epoch: 2,	learning_rate: 8.3567536564382e-06
2024-09-10 19:25:19 [INFO]   loss: 0.1022,	steps: 900/3804,	epoch: 2,	learning_rate: 8.32807570977918e-06
2024-09-10 19:25:24 [INFO]   loss: 0.0530,	steps: 910/3804,	epoch: 2,	learning_rate: 8.299397763120162e-06
2024-09-10 19:25:29 [INFO]   loss: 0.0994,	steps: 920/3804,	epoch: 2,	learning_rate: 8.270719816461142e-06
2024-09-10 19:25:34 [INFO]   loss: 0.0250,	steps: 930/3804,	epoch: 2,	learning_rate: 8.242041869802123e-06
2024-09-10 19:25:39 [INFO]   loss: 0.0818,	steps: 940/3804,	epoch: 2,	learning_rate: 8.213363923143103e-06
2024-09-10 19:25:44 [INFO]   loss: 0.0451,	steps: 950/3804,	epoch: 2,	learning_rate: 8.184685976484085e-06
2024-09-10 19:36:30 [INFO]   第2轮的训练 测试结果为：{'R@5': 0.5194826428149777, 'R@10': 0.6906987732436641, 'RR@5': 0.8387254901960796, 'RR@10': 0.8420554680205425, 'nDCG@5': 0.624342199761005, 'nDCG@10': 0.6774824503626862}
2024-09-10 19:36:34 [INFO]   ------------------------------------------------
2024-09-10 19:36:34 [INFO]   第 2 轮已经训练完成  模型保存在 /mnt/workspace/clir/baselines/cross-mbert/output/best_model
2024-09-10 19:36:34 [INFO]   ------------------------------------------------
2024-09-10 19:36:38 [INFO]   loss: 0.0314,	steps: 960/3804,	epoch: 3,	learning_rate: 8.156008029825065e-06
2024-09-10 19:36:43 [INFO]   loss: 0.0159,	steps: 970/3804,	epoch: 3,	learning_rate: 8.127330083166046e-06
2024-09-10 19:36:48 [INFO]   loss: 0.0024,	steps: 980/3804,	epoch: 3,	learning_rate: 8.098652136507026e-06
2024-09-10 19:36:53 [INFO]   loss: 0.0075,	steps: 990/3804,	epoch: 3,	learning_rate: 8.069974189848008e-06
2024-09-10 19:36:58 [INFO]   loss: 0.0162,	steps: 1000/3804,	epoch: 3,	learning_rate: 8.041296243188988e-06
2024-09-10 19:37:03 [INFO]   loss: 0.0110,	steps: 1010/3804,	epoch: 3,	learning_rate: 8.01261829652997e-06
2024-09-10 19:37:07 [INFO]   loss: 0.0225,	steps: 1020/3804,	epoch: 3,	learning_rate: 7.98394034987095e-06
2024-09-10 19:37:12 [INFO]   loss: 0.0030,	steps: 1030/3804,	epoch: 3,	learning_rate: 7.955262403211931e-06
2024-09-10 19:37:17 [INFO]   loss: 0.0414,	steps: 1040/3804,	epoch: 3,	learning_rate: 7.926584456552911e-06
2024-09-10 19:37:22 [INFO]   loss: 0.0672,	steps: 1050/3804,	epoch: 3,	learning_rate: 7.897906509893893e-06
2024-09-10 19:37:27 [INFO]   loss: 0.0682,	steps: 1060/3804,	epoch: 3,	learning_rate: 7.869228563234872e-06
2024-09-10 19:37:32 [INFO]   loss: 0.0141,	steps: 1070/3804,	epoch: 3,	learning_rate: 7.840550616575854e-06
2024-09-10 19:37:37 [INFO]   loss: 0.0056,	steps: 1080/3804,	epoch: 3,	learning_rate: 7.811872669916834e-06
2024-09-10 19:37:42 [INFO]   loss: 0.0493,	steps: 1090/3804,	epoch: 3,	learning_rate: 7.783194723257816e-06
2024-09-10 19:37:47 [INFO]   loss: 0.0250,	steps: 1100/3804,	epoch: 3,	learning_rate: 7.754516776598795e-06
2024-09-10 19:37:52 [INFO]   loss: 0.0028,	steps: 1110/3804,	epoch: 3,	learning_rate: 7.725838829939777e-06
2024-09-10 19:37:57 [INFO]   loss: 0.0065,	steps: 1120/3804,	epoch: 3,	learning_rate: 7.697160883280757e-06
2024-09-10 19:38:02 [INFO]   loss: 0.0186,	steps: 1130/3804,	epoch: 3,	learning_rate: 7.668482936621739e-06
2024-09-10 19:38:07 [INFO]   loss: 0.0136,	steps: 1140/3804,	epoch: 3,	learning_rate: 7.639804989962718e-06
2024-09-10 19:38:12 [INFO]   loss: 0.0468,	steps: 1150/3804,	epoch: 3,	learning_rate: 7.6111270433037e-06
2024-09-10 19:38:17 [INFO]   loss: 0.0035,	steps: 1160/3804,	epoch: 3,	learning_rate: 7.582449096644681e-06
2024-09-10 19:38:22 [INFO]   loss: 0.0004,	steps: 1170/3804,	epoch: 3,	learning_rate: 7.553771149985662e-06
2024-09-10 19:38:27 [INFO]   loss: 0.0035,	steps: 1180/3804,	epoch: 3,	learning_rate: 7.525093203326642e-06
2024-09-10 19:38:31 [INFO]   loss: 0.0016,	steps: 1190/3804,	epoch: 3,	learning_rate: 7.496415256667623e-06
2024-09-10 19:38:36 [INFO]   loss: 0.0021,	steps: 1200/3804,	epoch: 3,	learning_rate: 7.467737310008604e-06
2024-09-10 19:38:41 [INFO]   loss: 0.0042,	steps: 1210/3804,	epoch: 3,	learning_rate: 7.439059363349585e-06
2024-09-10 19:38:46 [INFO]   loss: 0.0043,	steps: 1220/3804,	epoch: 3,	learning_rate: 7.410381416690565e-06
2024-09-10 19:38:51 [INFO]   loss: 0.0078,	steps: 1230/3804,	epoch: 3,	learning_rate: 7.381703470031546e-06
2024-09-10 19:38:56 [INFO]   loss: 0.0092,	steps: 1240/3804,	epoch: 3,	learning_rate: 7.353025523372527e-06
2024-09-10 19:39:01 [INFO]   loss: 0.0065,	steps: 1250/3804,	epoch: 3,	learning_rate: 7.324347576713508e-06
2024-09-10 19:39:06 [INFO]   loss: 0.0019,	steps: 1260/3804,	epoch: 3,	learning_rate: 7.295669630054488e-06
2024-09-10 19:49:55 [INFO]   第3轮的训练 测试结果为：{'R@5': 0.5054512679394819, 'R@10': 0.6845756631332254, 'RR@5': 0.7871170343137261, 'RR@10': 0.7911688112745104, 'nDCG@5': 0.5774120485227333, 'nDCG@10': 0.6388129890300192}
2024-09-10 19:49:56 [INFO]   loss: 0.0252,	steps: 1270/3804,	epoch: 4,	learning_rate: 7.266991683395469e-06
2024-09-10 19:50:01 [INFO]   loss: 0.0187,	steps: 1280/3804,	epoch: 4,	learning_rate: 7.23831373673645e-06
2024-09-10 19:50:06 [INFO]   loss: 0.0005,	steps: 1290/3804,	epoch: 4,	learning_rate: 7.209635790077431e-06
2024-09-10 19:50:11 [INFO]   loss: 0.0010,	steps: 1300/3804,	epoch: 4,	learning_rate: 7.180957843418411e-06
2024-09-10 19:50:16 [INFO]   loss: 0.0002,	steps: 1310/3804,	epoch: 4,	learning_rate: 7.152279896759393e-06
2024-09-10 19:50:21 [INFO]   loss: 0.0108,	steps: 1320/3804,	epoch: 4,	learning_rate: 7.123601950100374e-06
2024-09-10 19:50:26 [INFO]   loss: 0.0170,	steps: 1330/3804,	epoch: 4,	learning_rate: 7.0949240034413545e-06
2024-09-10 19:50:31 [INFO]   loss: 0.0005,	steps: 1340/3804,	epoch: 4,	learning_rate: 7.066246056782335e-06
2024-09-10 19:50:36 [INFO]   loss: 0.0007,	steps: 1350/3804,	epoch: 4,	learning_rate: 7.037568110123316e-06
2024-09-10 19:50:41 [INFO]   loss: 0.0184,	steps: 1360/3804,	epoch: 4,	learning_rate: 7.008890163464297e-06
2024-09-10 19:50:45 [INFO]   loss: 0.0016,	steps: 1370/3804,	epoch: 4,	learning_rate: 6.9802122168052776e-06
2024-09-10 19:50:50 [INFO]   loss: 0.0001,	steps: 1380/3804,	epoch: 4,	learning_rate: 6.951534270146258e-06
2024-09-10 19:50:55 [INFO]   loss: 0.0010,	steps: 1390/3804,	epoch: 4,	learning_rate: 6.922856323487239e-06
2024-09-10 19:51:00 [INFO]   loss: 0.0544,	steps: 1400/3804,	epoch: 4,	learning_rate: 6.89417837682822e-06
2024-09-10 19:51:05 [INFO]   loss: 0.0337,	steps: 1410/3804,	epoch: 4,	learning_rate: 6.865500430169201e-06
2024-09-10 19:51:10 [INFO]   loss: 0.0398,	steps: 1420/3804,	epoch: 4,	learning_rate: 6.836822483510181e-06
2024-09-10 19:51:15 [INFO]   loss: 0.0102,	steps: 1430/3804,	epoch: 4,	learning_rate: 6.808144536851162e-06
2024-09-10 19:51:20 [INFO]   loss: 0.0072,	steps: 1440/3804,	epoch: 4,	learning_rate: 6.779466590192143e-06
2024-09-10 19:51:25 [INFO]   loss: 0.0013,	steps: 1450/3804,	epoch: 4,	learning_rate: 6.750788643533124e-06
2024-09-10 19:51:30 [INFO]   loss: 0.0024,	steps: 1460/3804,	epoch: 4,	learning_rate: 6.722110696874104e-06
2024-09-10 19:51:35 [INFO]   loss: 0.0009,	steps: 1470/3804,	epoch: 4,	learning_rate: 6.693432750215085e-06
2024-09-10 19:51:40 [INFO]   loss: 0.0308,	steps: 1480/3804,	epoch: 4,	learning_rate: 6.664754803556066e-06
2024-09-10 19:51:45 [INFO]   loss: 0.0020,	steps: 1490/3804,	epoch: 4,	learning_rate: 6.636076856897047e-06
2024-09-10 19:51:50 [INFO]   loss: 0.0829,	steps: 1500/3804,	epoch: 4,	learning_rate: 6.607398910238027e-06
2024-09-10 19:51:55 [INFO]   loss: 0.0186,	steps: 1510/3804,	epoch: 4,	learning_rate: 6.578720963579008e-06
2024-09-10 19:51:59 [INFO]   loss: 0.0031,	steps: 1520/3804,	epoch: 4,	learning_rate: 6.550043016919989e-06
2024-09-10 19:52:04 [INFO]   loss: 0.0162,	steps: 1530/3804,	epoch: 4,	learning_rate: 6.52136507026097e-06
2024-09-10 19:52:09 [INFO]   loss: 0.0014,	steps: 1540/3804,	epoch: 4,	learning_rate: 6.49268712360195e-06
2024-09-10 19:52:14 [INFO]   loss: 0.0017,	steps: 1550/3804,	epoch: 4,	learning_rate: 6.464009176942931e-06
2024-09-10 19:52:19 [INFO]   loss: 0.0028,	steps: 1560/3804,	epoch: 4,	learning_rate: 6.435331230283912e-06
2024-09-10 19:52:24 [INFO]   loss: 0.0330,	steps: 1570/3804,	epoch: 4,	learning_rate: 6.406653283624893e-06
2024-09-10 19:52:29 [INFO]   loss: 0.0057,	steps: 1580/3804,	epoch: 4,	learning_rate: 6.3779753369658734e-06
2024-09-10 20:03:17 [INFO]   第4轮的训练 测试结果为：{'R@5': 0.5345632208267973, 'R@10': 0.7006810090801906, 'RR@5': 0.8423866421568633, 'RR@10': 0.845663734243698, 'nDCG@5': 0.6379962661713808, 'nDCG@10': 0.6878628920007492}
2024-09-10 20:03:20 [INFO]   ------------------------------------------------
2024-09-10 20:03:20 [INFO]   第 4 轮已经训练完成  模型保存在 /mnt/workspace/clir/baselines/cross-mbert/output/best_model
2024-09-10 20:03:20 [INFO]   ------------------------------------------------
2024-09-10 20:03:22 [INFO]   loss: 0.0025,	steps: 1590/3804,	epoch: 5,	learning_rate: 6.349297390306854e-06
2024-09-10 20:03:27 [INFO]   loss: 0.0008,	steps: 1600/3804,	epoch: 5,	learning_rate: 6.320619443647835e-06
2024-09-10 20:03:32 [INFO]   loss: 0.0383,	steps: 1610/3804,	epoch: 5,	learning_rate: 6.291941496988816e-06
2024-09-10 20:03:37 [INFO]   loss: 0.0005,	steps: 1620/3804,	epoch: 5,	learning_rate: 6.2632635503297965e-06
2024-09-10 20:03:42 [INFO]   loss: 0.0030,	steps: 1630/3804,	epoch: 5,	learning_rate: 6.234585603670777e-06
2024-09-10 20:03:47 [INFO]   loss: 0.0006,	steps: 1640/3804,	epoch: 5,	learning_rate: 6.205907657011758e-06
2024-09-10 20:03:52 [INFO]   loss: 0.0431,	steps: 1650/3804,	epoch: 5,	learning_rate: 6.177229710352739e-06
2024-09-10 20:03:57 [INFO]   loss: 0.0007,	steps: 1660/3804,	epoch: 5,	learning_rate: 6.1485517636937195e-06
2024-09-10 20:04:02 [INFO]   loss: 0.0006,	steps: 1670/3804,	epoch: 5,	learning_rate: 6.1198738170347e-06
2024-09-10 20:04:07 [INFO]   loss: 0.0424,	steps: 1680/3804,	epoch: 5,	learning_rate: 6.091195870375681e-06
2024-09-10 20:04:12 [INFO]   loss: 0.0000,	steps: 1690/3804,	epoch: 5,	learning_rate: 6.062517923716662e-06
2024-09-10 20:04:17 [INFO]   loss: 0.0039,	steps: 1700/3804,	epoch: 5,	learning_rate: 6.0338399770576425e-06
2024-09-10 20:04:22 [INFO]   loss: 0.0079,	steps: 1710/3804,	epoch: 5,	learning_rate: 6.005162030398623e-06
2024-09-10 20:04:27 [INFO]   loss: 0.0003,	steps: 1720/3804,	epoch: 5,	learning_rate: 5.976484083739604e-06
2024-09-10 20:04:32 [INFO]   loss: 0.0011,	steps: 1730/3804,	epoch: 5,	learning_rate: 5.947806137080585e-06
2024-09-10 20:04:37 [INFO]   loss: 0.0005,	steps: 1740/3804,	epoch: 5,	learning_rate: 5.9191281904215655e-06
2024-09-10 20:04:42 [INFO]   loss: 0.0076,	steps: 1750/3804,	epoch: 5,	learning_rate: 5.890450243762546e-06
2024-09-10 20:04:46 [INFO]   loss: 0.1156,	steps: 1760/3804,	epoch: 5,	learning_rate: 5.861772297103527e-06
2024-09-10 20:04:51 [INFO]   loss: 0.0001,	steps: 1770/3804,	epoch: 5,	learning_rate: 5.833094350444508e-06
2024-09-10 20:04:56 [INFO]   loss: 0.0107,	steps: 1780/3804,	epoch: 5,	learning_rate: 5.80441640378549e-06
2024-09-10 20:05:01 [INFO]   loss: 0.0055,	steps: 1790/3804,	epoch: 5,	learning_rate: 5.775738457126471e-06
2024-09-10 20:05:06 [INFO]   loss: 0.0002,	steps: 1800/3804,	epoch: 5,	learning_rate: 5.747060510467452e-06
2024-09-10 20:05:11 [INFO]   loss: 0.0007,	steps: 1810/3804,	epoch: 5,	learning_rate: 5.7183825638084325e-06
2024-09-10 20:05:16 [INFO]   loss: 0.0100,	steps: 1820/3804,	epoch: 5,	learning_rate: 5.689704617149413e-06
2024-09-10 20:05:21 [INFO]   loss: 0.0026,	steps: 1830/3804,	epoch: 5,	learning_rate: 5.661026670490394e-06
2024-09-10 20:05:26 [INFO]   loss: 0.0013,	steps: 1840/3804,	epoch: 5,	learning_rate: 5.632348723831375e-06
2024-09-10 20:05:31 [INFO]   loss: 0.0006,	steps: 1850/3804,	epoch: 5,	learning_rate: 5.6036707771723555e-06
2024-09-10 20:05:36 [INFO]   loss: 0.0028,	steps: 1860/3804,	epoch: 5,	learning_rate: 5.574992830513336e-06
2024-09-10 20:05:41 [INFO]   loss: 0.0013,	steps: 1870/3804,	epoch: 5,	learning_rate: 5.546314883854317e-06
2024-09-10 20:05:45 [INFO]   loss: 0.0045,	steps: 1880/3804,	epoch: 5,	learning_rate: 5.517636937195298e-06
2024-09-10 20:05:50 [INFO]   loss: 0.0026,	steps: 1890/3804,	epoch: 5,	learning_rate: 5.4889589905362786e-06
2024-09-10 20:05:55 [INFO]   loss: 0.0094,	steps: 1900/3804,	epoch: 5,	learning_rate: 5.460281043877259e-06
2024-09-10 20:16:42 [INFO]   第5轮的训练 测试结果为：{'R@5': 0.5216008885623875, 'R@10': 0.6944861985773466, 'RR@5': 0.8308823529411771, 'RR@10': 0.8352729633520078, 'nDCG@5': 0.6205742205239562, 'nDCG@10': 0.6715373063173998}
2024-09-10 20:16:46 [INFO]   loss: 0.0001,	steps: 1910/3804,	epoch: 6,	learning_rate: 5.43160309721824e-06
2024-09-10 20:16:51 [INFO]   loss: 0.0001,	steps: 1920/3804,	epoch: 6,	learning_rate: 5.402925150559221e-06
2024-09-10 20:16:56 [INFO]   loss: 0.0022,	steps: 1930/3804,	epoch: 6,	learning_rate: 5.374247203900202e-06
2024-09-10 20:17:00 [INFO]   loss: 0.0001,	steps: 1940/3804,	epoch: 6,	learning_rate: 5.345569257241182e-06
2024-09-10 20:17:05 [INFO]   loss: 0.0001,	steps: 1950/3804,	epoch: 6,	learning_rate: 5.316891310582163e-06
2024-09-10 20:17:10 [INFO]   loss: 0.0050,	steps: 1960/3804,	epoch: 6,	learning_rate: 5.288213363923144e-06
2024-09-10 20:17:15 [INFO]   loss: 0.0004,	steps: 1970/3804,	epoch: 6,	learning_rate: 5.259535417264125e-06
2024-09-10 20:17:20 [INFO]   loss: 0.0001,	steps: 1980/3804,	epoch: 6,	learning_rate: 5.230857470605105e-06
2024-09-10 20:17:25 [INFO]   loss: 0.0000,	steps: 1990/3804,	epoch: 6,	learning_rate: 5.202179523946086e-06
2024-09-10 20:17:30 [INFO]   loss: 0.0001,	steps: 2000/3804,	epoch: 6,	learning_rate: 5.173501577287067e-06
2024-09-10 20:17:35 [INFO]   loss: 0.0002,	steps: 2010/3804,	epoch: 6,	learning_rate: 5.144823630628048e-06
2024-09-10 20:17:40 [INFO]   loss: 0.0015,	steps: 2020/3804,	epoch: 6,	learning_rate: 5.116145683969028e-06
2024-09-10 20:17:45 [INFO]   loss: 0.0002,	steps: 2030/3804,	epoch: 6,	learning_rate: 5.087467737310009e-06
2024-09-10 20:17:50 [INFO]   loss: 0.0002,	steps: 2040/3804,	epoch: 6,	learning_rate: 5.05878979065099e-06
2024-09-10 20:17:55 [INFO]   loss: 0.0001,	steps: 2050/3804,	epoch: 6,	learning_rate: 5.030111843991971e-06
2024-09-10 20:18:00 [INFO]   loss: 0.0000,	steps: 2060/3804,	epoch: 6,	learning_rate: 5.001433897332951e-06
2024-09-10 20:18:05 [INFO]   loss: 0.0016,	steps: 2070/3804,	epoch: 6,	learning_rate: 4.972755950673932e-06
2024-09-10 20:18:10 [INFO]   loss: 0.0003,	steps: 2080/3804,	epoch: 6,	learning_rate: 4.944078004014913e-06
2024-09-10 20:18:15 [INFO]   loss: 0.0001,	steps: 2090/3804,	epoch: 6,	learning_rate: 4.915400057355894e-06
2024-09-10 20:18:20 [INFO]   loss: 0.0000,	steps: 2100/3804,	epoch: 6,	learning_rate: 4.8867221106968744e-06
2024-09-10 20:18:25 [INFO]   loss: 0.0001,	steps: 2110/3804,	epoch: 6,	learning_rate: 4.858044164037855e-06
2024-09-10 20:18:29 [INFO]   loss: 0.0001,	steps: 2120/3804,	epoch: 6,	learning_rate: 4.829366217378836e-06
2024-09-10 20:18:34 [INFO]   loss: 0.0080,	steps: 2130/3804,	epoch: 6,	learning_rate: 4.800688270719817e-06
2024-09-10 20:18:39 [INFO]   loss: 0.0049,	steps: 2140/3804,	epoch: 6,	learning_rate: 4.772010324060798e-06
2024-09-10 20:18:44 [INFO]   loss: 0.0117,	steps: 2150/3804,	epoch: 6,	learning_rate: 4.743332377401779e-06
2024-09-10 20:18:49 [INFO]   loss: 0.0010,	steps: 2160/3804,	epoch: 6,	learning_rate: 4.71465443074276e-06
2024-09-10 20:18:54 [INFO]   loss: 0.0006,	steps: 2170/3804,	epoch: 6,	learning_rate: 4.6859764840837406e-06
2024-09-10 20:18:59 [INFO]   loss: 0.0065,	steps: 2180/3804,	epoch: 6,	learning_rate: 4.657298537424721e-06
2024-09-10 20:19:04 [INFO]   loss: 0.0006,	steps: 2190/3804,	epoch: 6,	learning_rate: 4.628620590765702e-06
2024-09-10 20:19:09 [INFO]   loss: 0.0001,	steps: 2200/3804,	epoch: 6,	learning_rate: 4.599942644106683e-06
2024-09-10 20:19:14 [INFO]   loss: 0.0003,	steps: 2210/3804,	epoch: 6,	learning_rate: 4.571264697447664e-06
2024-09-10 20:30:04 [INFO]   第6轮的训练 测试结果为：{'R@5': 0.53190864434854, 'R@10': 0.7006704232362124, 'RR@5': 0.8448988970588239, 'RR@10': 0.8486282533846877, 'nDCG@5': 0.641110646449688, 'nDCG@10': 0.69064445634033}
2024-09-10 20:30:07 [INFO]   ------------------------------------------------
2024-09-10 20:30:07 [INFO]   第 6 轮已经训练完成  模型保存在 /mnt/workspace/clir/baselines/cross-mbert/output/best_model
2024-09-10 20:30:07 [INFO]   ------------------------------------------------
2024-09-10 20:30:08 [INFO]   loss: 0.0037,	steps: 2220/3804,	epoch: 7,	learning_rate: 4.542586750788644e-06
2024-09-10 20:30:12 [INFO]   loss: 0.0000,	steps: 2230/3804,	epoch: 7,	learning_rate: 4.513908804129625e-06
2024-09-10 20:30:17 [INFO]   loss: 0.0002,	steps: 2240/3804,	epoch: 7,	learning_rate: 4.485230857470606e-06
2024-09-10 20:30:22 [INFO]   loss: 0.0000,	steps: 2250/3804,	epoch: 7,	learning_rate: 4.456552910811587e-06
2024-09-10 20:30:27 [INFO]   loss: 0.0021,	steps: 2260/3804,	epoch: 7,	learning_rate: 4.427874964152567e-06
2024-09-10 20:30:32 [INFO]   loss: 0.0000,	steps: 2270/3804,	epoch: 7,	learning_rate: 4.399197017493548e-06
2024-09-10 20:30:37 [INFO]   loss: 0.0005,	steps: 2280/3804,	epoch: 7,	learning_rate: 4.370519070834529e-06
2024-09-10 20:30:42 [INFO]   loss: 0.0004,	steps: 2290/3804,	epoch: 7,	learning_rate: 4.34184112417551e-06
2024-09-10 20:30:47 [INFO]   loss: 0.0000,	steps: 2300/3804,	epoch: 7,	learning_rate: 4.31316317751649e-06
2024-09-10 20:30:52 [INFO]   loss: 0.0002,	steps: 2310/3804,	epoch: 7,	learning_rate: 4.284485230857471e-06
2024-09-10 20:30:57 [INFO]   loss: 0.0028,	steps: 2320/3804,	epoch: 7,	learning_rate: 4.255807284198452e-06
2024-09-10 20:31:02 [INFO]   loss: 0.0001,	steps: 2330/3804,	epoch: 7,	learning_rate: 4.227129337539433e-06
2024-09-10 20:31:07 [INFO]   loss: 0.0004,	steps: 2340/3804,	epoch: 7,	learning_rate: 4.1984513908804134e-06
2024-09-10 20:31:12 [INFO]   loss: 0.0007,	steps: 2350/3804,	epoch: 7,	learning_rate: 4.169773444221394e-06
2024-09-10 20:31:16 [INFO]   loss: 0.0038,	steps: 2360/3804,	epoch: 7,	learning_rate: 4.141095497562375e-06
2024-09-10 20:31:21 [INFO]   loss: 0.0112,	steps: 2370/3804,	epoch: 7,	learning_rate: 4.112417550903356e-06
2024-09-10 20:31:26 [INFO]   loss: 0.0007,	steps: 2380/3804,	epoch: 7,	learning_rate: 4.0837396042443365e-06
2024-09-10 20:31:31 [INFO]   loss: 0.0019,	steps: 2390/3804,	epoch: 7,	learning_rate: 4.055061657585317e-06
2024-09-10 20:31:36 [INFO]   loss: 0.0000,	steps: 2400/3804,	epoch: 7,	learning_rate: 4.026383710926298e-06
2024-09-10 20:31:41 [INFO]   loss: 0.0001,	steps: 2410/3804,	epoch: 7,	learning_rate: 3.997705764267279e-06
2024-09-10 20:31:46 [INFO]   loss: 0.0286,	steps: 2420/3804,	epoch: 7,	learning_rate: 3.9690278176082595e-06
2024-09-10 20:31:51 [INFO]   loss: 0.0000,	steps: 2430/3804,	epoch: 7,	learning_rate: 3.94034987094924e-06
2024-09-10 20:31:56 [INFO]   loss: 0.0000,	steps: 2440/3804,	epoch: 7,	learning_rate: 3.911671924290221e-06
2024-09-10 20:32:01 [INFO]   loss: 0.0000,	steps: 2450/3804,	epoch: 7,	learning_rate: 3.882993977631202e-06
2024-09-10 20:32:05 [INFO]   loss: 0.0004,	steps: 2460/3804,	epoch: 7,	learning_rate: 3.8543160309721825e-06
2024-09-10 20:32:10 [INFO]   loss: 0.0007,	steps: 2470/3804,	epoch: 7,	learning_rate: 3.825638084313163e-06
2024-09-10 20:32:15 [INFO]   loss: 0.0059,	steps: 2480/3804,	epoch: 7,	learning_rate: 3.7969601376541444e-06
2024-09-10 20:32:20 [INFO]   loss: 0.0011,	steps: 2490/3804,	epoch: 7,	learning_rate: 3.768282190995125e-06
2024-09-10 20:32:25 [INFO]   loss: 0.0011,	steps: 2500/3804,	epoch: 7,	learning_rate: 3.739604244336106e-06
2024-09-10 20:32:30 [INFO]   loss: 0.0003,	steps: 2510/3804,	epoch: 7,	learning_rate: 3.7109262976770867e-06
2024-09-10 20:32:35 [INFO]   loss: 0.0003,	steps: 2520/3804,	epoch: 7,	learning_rate: 3.6822483510180675e-06
2024-09-10 20:32:40 [INFO]   loss: 0.0022,	steps: 2530/3804,	epoch: 7,	learning_rate: 3.6535704043590482e-06
2024-09-10 20:43:28 [INFO]   第7轮的训练 测试结果为：{'R@5': 0.5405528317134719, 'R@10': 0.7055386742431891, 'RR@5': 0.8471200980392162, 'RR@10': 0.8500966532446314, 'nDCG@5': 0.6475059995563808, 'nDCG@10': 0.6951535534952011}
2024-09-10 20:43:31 [INFO]   ------------------------------------------------
2024-09-10 20:43:31 [INFO]   第 7 轮已经训练完成  模型保存在 /mnt/workspace/clir/baselines/cross-mbert/output/best_model
2024-09-10 20:43:31 [INFO]   ------------------------------------------------
2024-09-10 20:43:33 [INFO]   loss: 0.0000,	steps: 2540/3804,	epoch: 8,	learning_rate: 3.624892457700029e-06
2024-09-10 20:43:38 [INFO]   loss: 0.0014,	steps: 2550/3804,	epoch: 8,	learning_rate: 3.5962145110410097e-06
2024-09-10 20:43:43 [INFO]   loss: 0.0003,	steps: 2560/3804,	epoch: 8,	learning_rate: 3.5675365643819905e-06
2024-09-10 20:43:48 [INFO]   loss: 0.0002,	steps: 2570/3804,	epoch: 8,	learning_rate: 3.5388586177229712e-06
2024-09-10 20:43:53 [INFO]   loss: 0.0003,	steps: 2580/3804,	epoch: 8,	learning_rate: 3.510180671063952e-06
2024-09-10 20:43:58 [INFO]   loss: 0.0185,	steps: 2590/3804,	epoch: 8,	learning_rate: 3.4815027244049328e-06
2024-09-10 20:44:03 [INFO]   loss: 0.0004,	steps: 2600/3804,	epoch: 8,	learning_rate: 3.4528247777459135e-06
2024-09-10 20:44:08 [INFO]   loss: 0.0000,	steps: 2610/3804,	epoch: 8,	learning_rate: 3.4241468310868947e-06
2024-09-10 20:44:13 [INFO]   loss: 0.0017,	steps: 2620/3804,	epoch: 8,	learning_rate: 3.3954688844278754e-06
2024-09-10 20:44:17 [INFO]   loss: 0.0053,	steps: 2630/3804,	epoch: 8,	learning_rate: 3.366790937768856e-06
2024-09-10 20:44:22 [INFO]   loss: 0.0003,	steps: 2640/3804,	epoch: 8,	learning_rate: 3.338112991109837e-06
2024-09-10 20:44:27 [INFO]   loss: 0.0030,	steps: 2650/3804,	epoch: 8,	learning_rate: 3.3094350444508177e-06
2024-09-10 20:44:32 [INFO]   loss: 0.0015,	steps: 2660/3804,	epoch: 8,	learning_rate: 3.2807570977917985e-06
2024-09-10 20:44:37 [INFO]   loss: 0.0000,	steps: 2670/3804,	epoch: 8,	learning_rate: 3.2520791511327792e-06
2024-09-10 20:44:42 [INFO]   loss: 0.0002,	steps: 2680/3804,	epoch: 8,	learning_rate: 3.22340120447376e-06
2024-09-10 20:44:47 [INFO]   loss: 0.0000,	steps: 2690/3804,	epoch: 8,	learning_rate: 3.1947232578147407e-06
2024-09-10 20:44:52 [INFO]   loss: 0.0000,	steps: 2700/3804,	epoch: 8,	learning_rate: 3.1660453111557215e-06
2024-09-10 20:44:57 [INFO]   loss: 0.0000,	steps: 2710/3804,	epoch: 8,	learning_rate: 3.1373673644967022e-06
2024-09-10 20:45:02 [INFO]   loss: 0.0001,	steps: 2720/3804,	epoch: 8,	learning_rate: 3.108689417837683e-06
2024-09-10 20:45:07 [INFO]   loss: 0.0001,	steps: 2730/3804,	epoch: 8,	learning_rate: 3.0800114711786638e-06
2024-09-10 20:45:12 [INFO]   loss: 0.0009,	steps: 2740/3804,	epoch: 8,	learning_rate: 3.0513335245196445e-06
2024-09-10 20:45:16 [INFO]   loss: 0.0000,	steps: 2750/3804,	epoch: 8,	learning_rate: 3.0226555778606253e-06
2024-09-10 20:45:21 [INFO]   loss: 0.0000,	steps: 2760/3804,	epoch: 8,	learning_rate: 2.993977631201606e-06
2024-09-10 20:45:26 [INFO]   loss: 0.0001,	steps: 2770/3804,	epoch: 8,	learning_rate: 2.9652996845425868e-06
2024-09-10 20:45:31 [INFO]   loss: 0.0000,	steps: 2780/3804,	epoch: 8,	learning_rate: 2.9366217378835675e-06
2024-09-10 20:45:36 [INFO]   loss: 0.0004,	steps: 2790/3804,	epoch: 8,	learning_rate: 2.9079437912245483e-06
2024-09-10 20:45:41 [INFO]   loss: 0.0002,	steps: 2800/3804,	epoch: 8,	learning_rate: 2.879265844565529e-06
2024-09-10 20:45:46 [INFO]   loss: 0.0002,	steps: 2810/3804,	epoch: 8,	learning_rate: 2.85058789790651e-06
2024-09-10 20:45:51 [INFO]   loss: 0.0036,	steps: 2820/3804,	epoch: 8,	learning_rate: 2.8219099512474906e-06
2024-09-10 20:45:56 [INFO]   loss: 0.0012,	steps: 2830/3804,	epoch: 8,	learning_rate: 2.7932320045884713e-06
2024-09-10 20:46:00 [INFO]   loss: 0.0627,	steps: 2840/3804,	epoch: 8,	learning_rate: 2.764554057929453e-06
2024-09-10 20:46:05 [INFO]   loss: 0.0000,	steps: 2850/3804,	epoch: 8,	learning_rate: 2.7358761112704337e-06
2024-09-10 20:56:52 [INFO]   第8轮的训练 测试结果为：{'R@5': 0.5261491525059996, 'R@10': 0.7021204951321586, 'RR@5': 0.8346354166666672, 'RR@10': 0.8389279149159669, 'nDCG@5': 0.6286620751349993, 'nDCG@10': 0.682976698934658}
2024-09-10 20:56:56 [INFO]   loss: 0.0000,	steps: 2860/3804,	epoch: 9,	learning_rate: 2.7071981646114144e-06
2024-09-10 20:57:01 [INFO]   loss: 0.0023,	steps: 2870/3804,	epoch: 9,	learning_rate: 2.678520217952395e-06
2024-09-10 20:57:06 [INFO]   loss: 0.0054,	steps: 2880/3804,	epoch: 9,	learning_rate: 2.649842271293376e-06
2024-09-10 20:57:11 [INFO]   loss: 0.0000,	steps: 2890/3804,	epoch: 9,	learning_rate: 2.6211643246343567e-06
2024-09-10 20:57:15 [INFO]   loss: 0.0001,	steps: 2900/3804,	epoch: 9,	learning_rate: 2.5924863779753375e-06
2024-09-10 20:57:20 [INFO]   loss: 0.0001,	steps: 2910/3804,	epoch: 9,	learning_rate: 2.5638084313163182e-06
2024-09-10 20:57:25 [INFO]   loss: 0.0006,	steps: 2920/3804,	epoch: 9,	learning_rate: 2.535130484657299e-06
2024-09-10 20:57:30 [INFO]   loss: 0.0000,	steps: 2930/3804,	epoch: 9,	learning_rate: 2.5064525379982797e-06
2024-09-10 20:57:35 [INFO]   loss: 0.0002,	steps: 2940/3804,	epoch: 9,	learning_rate: 2.4777745913392605e-06
2024-09-10 20:57:40 [INFO]   loss: 0.0002,	steps: 2950/3804,	epoch: 9,	learning_rate: 2.4490966446802412e-06
2024-09-10 20:57:45 [INFO]   loss: 0.0000,	steps: 2960/3804,	epoch: 9,	learning_rate: 2.420418698021222e-06
2024-09-10 20:57:50 [INFO]   loss: 0.0000,	steps: 2970/3804,	epoch: 9,	learning_rate: 2.3917407513622027e-06
2024-09-10 20:57:55 [INFO]   loss: 0.0187,	steps: 2980/3804,	epoch: 9,	learning_rate: 2.3630628047031835e-06
2024-09-10 20:58:00 [INFO]   loss: 0.0000,	steps: 2990/3804,	epoch: 9,	learning_rate: 2.3343848580441643e-06
2024-09-10 20:58:05 [INFO]   loss: 0.0002,	steps: 3000/3804,	epoch: 9,	learning_rate: 2.305706911385145e-06
2024-09-10 20:58:10 [INFO]   loss: 0.0003,	steps: 3010/3804,	epoch: 9,	learning_rate: 2.2770289647261258e-06
2024-09-10 20:58:14 [INFO]   loss: 0.0000,	steps: 3020/3804,	epoch: 9,	learning_rate: 2.2483510180671065e-06
2024-09-10 20:58:19 [INFO]   loss: 0.0000,	steps: 3030/3804,	epoch: 9,	learning_rate: 2.2196730714080873e-06
2024-09-10 20:58:24 [INFO]   loss: 0.0002,	steps: 3040/3804,	epoch: 9,	learning_rate: 2.190995124749068e-06
2024-09-10 20:58:29 [INFO]   loss: 0.0002,	steps: 3050/3804,	epoch: 9,	learning_rate: 2.162317178090049e-06
2024-09-10 20:58:34 [INFO]   loss: 0.0007,	steps: 3060/3804,	epoch: 9,	learning_rate: 2.1336392314310296e-06
2024-09-10 20:58:39 [INFO]   loss: 0.0013,	steps: 3070/3804,	epoch: 9,	learning_rate: 2.1049612847720103e-06
2024-09-10 20:58:44 [INFO]   loss: 0.0000,	steps: 3080/3804,	epoch: 9,	learning_rate: 2.076283338112991e-06
2024-09-10 20:58:49 [INFO]   loss: 0.0001,	steps: 3090/3804,	epoch: 9,	learning_rate: 2.047605391453972e-06
2024-09-10 20:58:54 [INFO]   loss: 0.0001,	steps: 3100/3804,	epoch: 9,	learning_rate: 2.0189274447949526e-06
2024-09-10 20:58:58 [INFO]   loss: 0.0002,	steps: 3110/3804,	epoch: 9,	learning_rate: 1.9902494981359333e-06
2024-09-10 20:59:03 [INFO]   loss: 0.0001,	steps: 3120/3804,	epoch: 9,	learning_rate: 1.9615715514769145e-06
2024-09-10 20:59:08 [INFO]   loss: 0.0002,	steps: 3130/3804,	epoch: 9,	learning_rate: 1.9328936048178953e-06
2024-09-10 20:59:13 [INFO]   loss: 0.0000,	steps: 3140/3804,	epoch: 9,	learning_rate: 1.904215658158876e-06
2024-09-10 20:59:18 [INFO]   loss: 0.0002,	steps: 3150/3804,	epoch: 9,	learning_rate: 1.8755377114998568e-06
2024-09-10 20:59:23 [INFO]   loss: 0.0002,	steps: 3160/3804,	epoch: 9,	learning_rate: 1.8468597648408375e-06
2024-09-10 20:59:28 [INFO]   loss: 0.0137,	steps: 3170/3804,	epoch: 9,	learning_rate: 1.8181818181818183e-06
2024-09-10 21:10:13 [INFO]   第9轮的训练 测试结果为：{'R@5': 0.535797599618642, 'R@10': 0.7071417233853627, 'RR@5': 0.8389552696078441, 'RR@10': 0.8420809990662941, 'nDCG@5': 0.630782785139696, 'nDCG@10': 0.6831649752697726}
2024-09-10 21:10:18 [INFO]   loss: 0.0026,	steps: 3180/3804,	epoch: 10,	learning_rate: 1.789503871522799e-06
2024-09-10 21:10:23 [INFO]   loss: 0.0006,	steps: 3190/3804,	epoch: 10,	learning_rate: 1.7608259248637798e-06
2024-09-10 21:10:28 [INFO]   loss: 0.0002,	steps: 3200/3804,	epoch: 10,	learning_rate: 1.7321479782047606e-06
2024-09-10 21:10:33 [INFO]   loss: 0.0001,	steps: 3210/3804,	epoch: 10,	learning_rate: 1.7034700315457413e-06
2024-09-10 21:10:38 [INFO]   loss: 0.0000,	steps: 3220/3804,	epoch: 10,	learning_rate: 1.6747920848867223e-06
2024-09-10 21:10:42 [INFO]   loss: 0.0003,	steps: 3230/3804,	epoch: 10,	learning_rate: 1.646114138227703e-06
2024-09-10 21:10:47 [INFO]   loss: 0.0003,	steps: 3240/3804,	epoch: 10,	learning_rate: 1.6174361915686838e-06
2024-09-10 21:10:52 [INFO]   loss: 0.0000,	steps: 3250/3804,	epoch: 10,	learning_rate: 1.5887582449096646e-06
2024-09-10 21:10:57 [INFO]   loss: 0.0000,	steps: 3260/3804,	epoch: 10,	learning_rate: 1.5600802982506455e-06
2024-09-10 21:11:02 [INFO]   loss: 0.0012,	steps: 3270/3804,	epoch: 10,	learning_rate: 1.5314023515916263e-06
2024-09-10 21:11:07 [INFO]   loss: 0.0019,	steps: 3280/3804,	epoch: 10,	learning_rate: 1.502724404932607e-06
2024-09-10 21:11:12 [INFO]   loss: 0.0000,	steps: 3290/3804,	epoch: 10,	learning_rate: 1.4740464582735878e-06
2024-09-10 21:11:17 [INFO]   loss: 0.0000,	steps: 3300/3804,	epoch: 10,	learning_rate: 1.4453685116145685e-06
2024-09-10 21:11:22 [INFO]   loss: 0.0006,	steps: 3310/3804,	epoch: 10,	learning_rate: 1.4166905649555493e-06
2024-09-10 21:11:27 [INFO]   loss: 0.0008,	steps: 3320/3804,	epoch: 10,	learning_rate: 1.38801261829653e-06
2024-09-10 21:11:32 [INFO]   loss: 0.0003,	steps: 3330/3804,	epoch: 10,	learning_rate: 1.3593346716375108e-06
2024-09-10 21:11:37 [INFO]   loss: 0.0000,	steps: 3340/3804,	epoch: 10,	learning_rate: 1.3306567249784916e-06
2024-09-10 21:11:41 [INFO]   loss: 0.0000,	steps: 3350/3804,	epoch: 10,	learning_rate: 1.3019787783194723e-06
2024-09-10 21:11:46 [INFO]   loss: 0.0001,	steps: 3360/3804,	epoch: 10,	learning_rate: 1.273300831660453e-06
2024-09-10 21:11:51 [INFO]   loss: 0.0000,	steps: 3370/3804,	epoch: 10,	learning_rate: 1.244622885001434e-06
2024-09-10 21:11:56 [INFO]   loss: 0.0001,	steps: 3380/3804,	epoch: 10,	learning_rate: 1.2159449383424148e-06
2024-09-10 21:12:01 [INFO]   loss: 0.0000,	steps: 3390/3804,	epoch: 10,	learning_rate: 1.1872669916833956e-06
2024-09-10 21:12:06 [INFO]   loss: 0.0002,	steps: 3400/3804,	epoch: 10,	learning_rate: 1.1585890450243763e-06
2024-09-10 21:12:11 [INFO]   loss: 0.0000,	steps: 3410/3804,	epoch: 10,	learning_rate: 1.129911098365357e-06
2024-09-10 21:12:16 [INFO]   loss: 0.0003,	steps: 3420/3804,	epoch: 10,	learning_rate: 1.101233151706338e-06
2024-09-10 21:12:20 [INFO]   loss: 0.0001,	steps: 3430/3804,	epoch: 10,	learning_rate: 1.0725552050473188e-06
2024-09-10 21:12:25 [INFO]   loss: 0.0000,	steps: 3440/3804,	epoch: 10,	learning_rate: 1.0438772583882996e-06
2024-09-10 21:12:30 [INFO]   loss: 0.0001,	steps: 3450/3804,	epoch: 10,	learning_rate: 1.0151993117292803e-06
2024-09-10 21:12:35 [INFO]   loss: 0.0002,	steps: 3460/3804,	epoch: 10,	learning_rate: 9.86521365070261e-07
2024-09-10 21:12:40 [INFO]   loss: 0.0018,	steps: 3470/3804,	epoch: 10,	learning_rate: 9.578434184112418e-07
2024-09-10 21:12:45 [INFO]   loss: 0.0000,	steps: 3480/3804,	epoch: 10,	learning_rate: 9.291654717522227e-07
2024-09-10 21:23:34 [INFO]   第10轮的训练 测试结果为：{'R@5': 0.5357350787352565, 'R@10': 0.7064225591315664, 'RR@5': 0.8441023284313731, 'RR@10': 0.8480209792250237, 'nDCG@5': 0.6413433809554816, 'nDCG@10': 0.6935623191611455}
2024-09-10 21:23:35 [INFO]   loss: 0.0000,	steps: 3490/3804,	epoch: 11,	learning_rate: 9.004875250932034e-07
2024-09-10 21:23:40 [INFO]   loss: 0.0001,	steps: 3500/3804,	epoch: 11,	learning_rate: 8.718095784341842e-07
2024-09-10 21:23:45 [INFO]   loss: 0.0000,	steps: 3510/3804,	epoch: 11,	learning_rate: 8.43131631775165e-07
2024-09-10 21:23:50 [INFO]   loss: 0.0000,	steps: 3520/3804,	epoch: 11,	learning_rate: 8.144536851161458e-07
2024-09-10 21:23:55 [INFO]   loss: 0.0002,	steps: 3530/3804,	epoch: 11,	learning_rate: 7.857757384571266e-07
2024-09-10 21:23:59 [INFO]   loss: 0.0002,	steps: 3540/3804,	epoch: 11,	learning_rate: 7.570977917981073e-07
2024-09-10 21:24:04 [INFO]   loss: 0.0006,	steps: 3550/3804,	epoch: 11,	learning_rate: 7.284198451390881e-07
2024-09-10 21:24:09 [INFO]   loss: 0.0000,	steps: 3560/3804,	epoch: 11,	learning_rate: 6.997418984800688e-07
2024-09-10 21:24:14 [INFO]   loss: 0.0000,	steps: 3570/3804,	epoch: 11,	learning_rate: 6.710639518210496e-07
2024-09-10 21:24:19 [INFO]   loss: 0.0081,	steps: 3580/3804,	epoch: 11,	learning_rate: 6.423860051620306e-07
2024-09-10 21:24:24 [INFO]   loss: 0.0002,	steps: 3590/3804,	epoch: 11,	learning_rate: 6.137080585030113e-07
2024-09-10 21:24:29 [INFO]   loss: 0.0026,	steps: 3600/3804,	epoch: 11,	learning_rate: 5.850301118439921e-07
2024-09-10 21:24:34 [INFO]   loss: 0.0000,	steps: 3610/3804,	epoch: 11,	learning_rate: 5.563521651849728e-07
2024-09-10 21:24:39 [INFO]   loss: 0.0001,	steps: 3620/3804,	epoch: 11,	learning_rate: 5.276742185259536e-07
2024-09-10 21:24:44 [INFO]   loss: 0.0000,	steps: 3630/3804,	epoch: 11,	learning_rate: 4.989962718669343e-07
2024-09-10 21:24:49 [INFO]   loss: 0.0058,	steps: 3640/3804,	epoch: 11,	learning_rate: 4.7031832520791515e-07
2024-09-10 21:24:54 [INFO]   loss: 0.0043,	steps: 3650/3804,	epoch: 11,	learning_rate: 4.4164037854889596e-07
2024-09-10 21:24:58 [INFO]   loss: 0.0003,	steps: 3660/3804,	epoch: 11,	learning_rate: 4.129624318898767e-07
2024-09-10 21:25:03 [INFO]   loss: 0.0000,	steps: 3670/3804,	epoch: 11,	learning_rate: 3.8428448523085747e-07
2024-09-10 21:25:08 [INFO]   loss: 0.0000,	steps: 3680/3804,	epoch: 11,	learning_rate: 3.5560653857183833e-07
2024-09-10 21:25:13 [INFO]   loss: 0.0000,	steps: 3690/3804,	epoch: 11,	learning_rate: 3.269285919128191e-07
2024-09-10 21:25:18 [INFO]   loss: 0.0001,	steps: 3700/3804,	epoch: 11,	learning_rate: 2.982506452537999e-07
2024-09-10 21:25:23 [INFO]   loss: 0.0000,	steps: 3710/3804,	epoch: 11,	learning_rate: 2.6957269859478065e-07
2024-09-10 21:25:28 [INFO]   loss: 0.0002,	steps: 3720/3804,	epoch: 11,	learning_rate: 2.408947519357614e-07
2024-09-10 21:25:33 [INFO]   loss: 0.0001,	steps: 3730/3804,	epoch: 11,	learning_rate: 2.1221680527674222e-07
2024-09-10 21:25:37 [INFO]   loss: 0.0000,	steps: 3740/3804,	epoch: 11,	learning_rate: 1.8353885861772297e-07
2024-09-10 21:25:42 [INFO]   loss: 0.0044,	steps: 3750/3804,	epoch: 11,	learning_rate: 1.5486091195870378e-07
2024-09-10 21:25:47 [INFO]   loss: 0.0000,	steps: 3760/3804,	epoch: 11,	learning_rate: 1.2618296529968454e-07
2024-09-10 21:25:52 [INFO]   loss: 0.0001,	steps: 3770/3804,	epoch: 11,	learning_rate: 9.750501864066534e-08
2024-09-10 21:25:57 [INFO]   loss: 0.0000,	steps: 3780/3804,	epoch: 11,	learning_rate: 6.882707198164613e-08
2024-09-10 21:26:02 [INFO]   loss: 0.0029,	steps: 3790/3804,	epoch: 11,	learning_rate: 4.014912532262691e-08
2024-09-10 21:26:07 [INFO]   loss: 0.0000,	steps: 3800/3804,	epoch: 11,	learning_rate: 1.1471178663607686e-08
2024-09-10 21:36:54 [INFO]   第11轮的训练 测试结果为：{'R@5': 0.5386491508969633, 'R@10': 0.7091991797228292, 'RR@5': 0.8475030637254908, 'RR@10': 0.8510825163398698, 'nDCG@5': 0.647130072603131, 'nDCG@10': 0.6973773932267331}
2024-09-10 21:36:54 [INFO]   ------------------------------------------------
2024-09-10 21:36:54 [INFO]   所有epoch的平均评测指标为: {'R@5': 0.5196944698008571, 'R@10': 0.6903838835031723, 'RR@5': 0.8283509497549026, 'RR@10': 0.8323719070961725, 'nDCG@5': 0.6200870349821954, 'nDCG@10': 0.6721907080059935}
2024-09-10 21:36:54 [INFO]   ------------------------------------------------

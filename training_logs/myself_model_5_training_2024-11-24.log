2024-11-24 20:12:52 [INFO]   batch_size: 16, epoch: 16
2024-11-24 20:12:52 [INFO]   知识对比学习损失的权重: 0.6
2024-11-24 20:12:52 [INFO]   学习率:
2024-11-24 20:12:52 [INFO]       mbert 编码器: 1e-5
2024-11-24 20:12:52 [INFO]       query_knowledge_fusion: 1e-3
2024-11-24 20:12:52 [INFO]       GCN: 1e-3
2024-11-24 20:12:52 [INFO]       classifier: 1e-3
2024-11-24 20:12:52 [INFO]   v_kg: mean pooling
2024-11-24 20:12:52 [INFO]   相邻实体数量 3
2024-11-24 20:12:52 [INFO]   模块消融 实体信息对齐和实体信息聚合
2024-11-24 20:12:52 [INFO]   ***** Running training *****
2024-11-24 20:12:52 [INFO]   当前时间: 2024-11-24 20:12:52
2024-11-24 20:12:52 [INFO]   Num examples = 5087
2024-11-24 20:12:52 [INFO]   Num Epochs = 16
2024-11-24 20:12:52 [INFO]   Instantaneous batch size per device = 8
2024-11-24 20:12:52 [INFO]   Total train batch size (w. parallel, distributed & accumulation) = 16
2024-11-24 20:12:52 [INFO]   Total optimization steps = 10160
2024-11-24 20:12:52 [INFO]   训练的设备: cuda, 设备编号: 0
2024-11-24 20:13:17 [INFO]   loss: 2.4821,	steps: 50/10160,	epoch: 0,	learning_rate: 7.874015748031496e-07
2024-11-24 20:13:39 [INFO]   loss: 1.3275,	steps: 100/10160,	epoch: 0,	learning_rate: 1.5748031496062992e-06
2024-11-24 20:14:03 [INFO]   loss: 0.5857,	steps: 150/10160,	epoch: 0,	learning_rate: 2.362204724409449e-06
2024-11-24 20:14:27 [INFO]   loss: 0.6209,	steps: 200/10160,	epoch: 0,	learning_rate: 3.1496062992125985e-06
2024-11-24 20:14:50 [INFO]   loss: 0.5112,	steps: 250/10160,	epoch: 0,	learning_rate: 3.937007874015748e-06
2024-11-24 20:15:13 [INFO]   loss: 0.4353,	steps: 300/10160,	epoch: 0,	learning_rate: 4.724409448818898e-06
2024-11-24 20:15:37 [INFO]   loss: 0.4233,	steps: 350/10160,	epoch: 0,	learning_rate: 5.511811023622048e-06
2024-11-24 20:16:00 [INFO]   loss: 0.2582,	steps: 400/10160,	epoch: 0,	learning_rate: 6.299212598425197e-06
2024-11-24 20:16:24 [INFO]   loss: 0.1708,	steps: 450/10160,	epoch: 0,	learning_rate: 7.086614173228347e-06
2024-11-24 20:16:47 [INFO]   loss: 0.2268,	steps: 500/10160,	epoch: 0,	learning_rate: 7.874015748031496e-06
2024-11-24 20:17:11 [INFO]   loss: 0.4268,	steps: 550/10160,	epoch: 0,	learning_rate: 8.661417322834647e-06
2024-11-24 20:17:35 [INFO]   loss: 0.4412,	steps: 600/10160,	epoch: 0,	learning_rate: 9.448818897637797e-06
2024-11-24 20:42:21 [INFO]   第0轮的训练 测试结果为：{'R@5': 0.4783605202281002, 'R@10': 0.6468288354066367, 'RR@5': 0.7794883578431381, 'RR@10': 0.7859400531045758, 'nDCG@5': 0.5680158200275525, 'nDCG@10': 0.6196353795756366}
2024-11-24 20:42:22 [INFO]   ------------------------------------------------
2024-11-24 20:42:22 [INFO]   第 0 轮已经训练完成  模型保存在 /mnt/workspace/clir/myself/output/2024-11-24/best_model
2024-11-24 20:42:22 [INFO]   ------------------------------------------------
2024-11-24 20:42:29 [INFO]   loss: 0.2079,	steps: 650/10160,	epoch: 1,	learning_rate: 9.984251968503938e-06
2024-11-24 20:42:52 [INFO]   loss: 0.1831,	steps: 700/10160,	epoch: 1,	learning_rate: 9.931758530183728e-06
2024-11-24 20:43:16 [INFO]   loss: 0.1664,	steps: 750/10160,	epoch: 1,	learning_rate: 9.879265091863518e-06
2024-11-24 20:43:39 [INFO]   loss: 0.4475,	steps: 800/10160,	epoch: 1,	learning_rate: 9.826771653543308e-06
2024-11-24 20:44:02 [INFO]   loss: 0.1796,	steps: 850/10160,	epoch: 1,	learning_rate: 9.774278215223098e-06
2024-11-24 20:44:26 [INFO]   loss: 0.1743,	steps: 900/10160,	epoch: 1,	learning_rate: 9.721784776902888e-06
2024-11-24 20:44:50 [INFO]   loss: 0.2665,	steps: 950/10160,	epoch: 1,	learning_rate: 9.669291338582679e-06
2024-11-24 20:45:14 [INFO]   loss: 0.5177,	steps: 1000/10160,	epoch: 1,	learning_rate: 9.616797900262467e-06
2024-11-24 20:45:37 [INFO]   loss: 0.0430,	steps: 1050/10160,	epoch: 1,	learning_rate: 9.564304461942257e-06
2024-11-24 20:46:01 [INFO]   loss: 0.2007,	steps: 1100/10160,	epoch: 1,	learning_rate: 9.511811023622049e-06
2024-11-24 20:46:25 [INFO]   loss: 0.2398,	steps: 1150/10160,	epoch: 1,	learning_rate: 9.459317585301838e-06
2024-11-24 20:46:48 [INFO]   loss: 0.2907,	steps: 1200/10160,	epoch: 1,	learning_rate: 9.406824146981628e-06
2024-11-24 20:47:11 [INFO]   loss: 0.2809,	steps: 1250/10160,	epoch: 1,	learning_rate: 9.354330708661418e-06
2024-11-24 21:11:45 [INFO]   第1轮的训练 测试结果为：{'R@5': 0.379545970745743, 'R@10': 0.5625684582774662, 'RR@5': 0.5404105392156863, 'RR@10': 0.5547294438608781, 'nDCG@5': 0.4035206437144168, 'nDCG@10': 0.4808801945749445}
2024-11-24 21:11:59 [INFO]   loss: 0.3245,	steps: 1300/10160,	epoch: 2,	learning_rate: 9.301837270341208e-06
2024-11-24 21:12:23 [INFO]   loss: 0.1939,	steps: 1350/10160,	epoch: 2,	learning_rate: 9.249343832020998e-06
2024-11-24 21:12:46 [INFO]   loss: 0.2588,	steps: 1400/10160,	epoch: 2,	learning_rate: 9.196850393700788e-06
2024-11-24 21:13:09 [INFO]   loss: 0.2158,	steps: 1450/10160,	epoch: 2,	learning_rate: 9.144356955380579e-06
2024-11-24 21:13:33 [INFO]   loss: 0.1685,	steps: 1500/10160,	epoch: 2,	learning_rate: 9.091863517060369e-06
2024-11-24 21:13:56 [INFO]   loss: 0.2627,	steps: 1550/10160,	epoch: 2,	learning_rate: 9.039370078740159e-06
2024-11-24 21:14:20 [INFO]   loss: 0.6101,	steps: 1600/10160,	epoch: 2,	learning_rate: 8.986876640419947e-06
2024-11-24 21:14:43 [INFO]   loss: 0.4347,	steps: 1650/10160,	epoch: 2,	learning_rate: 8.934383202099738e-06
2024-11-24 21:15:07 [INFO]   loss: 0.2830,	steps: 1700/10160,	epoch: 2,	learning_rate: 8.88188976377953e-06
2024-11-24 21:15:30 [INFO]   loss: 0.2239,	steps: 1750/10160,	epoch: 2,	learning_rate: 8.829396325459318e-06
2024-11-24 21:15:54 [INFO]   loss: 0.1522,	steps: 1800/10160,	epoch: 2,	learning_rate: 8.776902887139108e-06
2024-11-24 21:16:17 [INFO]   loss: 0.1887,	steps: 1850/10160,	epoch: 2,	learning_rate: 8.724409448818898e-06
2024-11-24 21:16:40 [INFO]   loss: 0.2240,	steps: 1900/10160,	epoch: 2,	learning_rate: 8.671916010498688e-06
2024-11-24 21:41:08 [INFO]   第2轮的训练 测试结果为：{'R@5': 0.4503144288200582, 'R@10': 0.579845964786882, 'RR@5': 0.7570312500000007, 'RR@10': 0.7618361928104581, 'nDCG@5': 0.5494533283271559, 'nDCG@10': 0.5844129767333835}
2024-11-24 21:41:30 [INFO]   loss: 0.0900,	steps: 1950/10160,	epoch: 3,	learning_rate: 8.619422572178478e-06
2024-11-24 21:41:53 [INFO]   loss: 0.2622,	steps: 2000/10160,	epoch: 3,	learning_rate: 8.566929133858269e-06
2024-11-24 21:42:16 [INFO]   loss: 0.1376,	steps: 2050/10160,	epoch: 3,	learning_rate: 8.514435695538059e-06
2024-11-24 21:42:40 [INFO]   loss: 0.0718,	steps: 2100/10160,	epoch: 3,	learning_rate: 8.461942257217849e-06
2024-11-24 21:43:03 [INFO]   loss: 0.2911,	steps: 2150/10160,	epoch: 3,	learning_rate: 8.409448818897639e-06
2024-11-24 21:43:27 [INFO]   loss: 0.2830,	steps: 2200/10160,	epoch: 3,	learning_rate: 8.356955380577428e-06
2024-11-24 21:43:50 [INFO]   loss: 0.1287,	steps: 2250/10160,	epoch: 3,	learning_rate: 8.304461942257218e-06
2024-11-24 21:44:13 [INFO]   loss: 0.3407,	steps: 2300/10160,	epoch: 3,	learning_rate: 8.25196850393701e-06
2024-11-24 21:44:36 [INFO]   loss: 0.0612,	steps: 2350/10160,	epoch: 3,	learning_rate: 8.199475065616798e-06
2024-11-24 21:44:59 [INFO]   loss: 0.1441,	steps: 2400/10160,	epoch: 3,	learning_rate: 8.146981627296588e-06
2024-11-24 21:45:22 [INFO]   loss: 0.0737,	steps: 2450/10160,	epoch: 3,	learning_rate: 8.094488188976378e-06
2024-11-24 21:45:46 [INFO]   loss: 0.0426,	steps: 2500/10160,	epoch: 3,	learning_rate: 8.041994750656169e-06
2024-11-24 22:10:28 [INFO]   第3轮的训练 测试结果为：{'R@5': 0.47338585887668844, 'R@10': 0.6188308251084111, 'RR@5': 0.7943780637254909, 'RR@10': 0.7991622169701221, 'nDCG@5': 0.5779586103918416, 'nDCG@10': 0.6191224519405759}
2024-11-24 22:10:32 [INFO]   loss: 0.1805,	steps: 2550/10160,	epoch: 4,	learning_rate: 7.989501312335959e-06
2024-11-24 22:10:56 [INFO]   loss: 0.2104,	steps: 2600/10160,	epoch: 4,	learning_rate: 7.937007874015749e-06
2024-11-24 22:11:19 [INFO]   loss: 0.0993,	steps: 2650/10160,	epoch: 4,	learning_rate: 7.884514435695539e-06
2024-11-24 22:11:42 [INFO]   loss: 0.0797,	steps: 2700/10160,	epoch: 4,	learning_rate: 7.83202099737533e-06
2024-11-24 22:12:06 [INFO]   loss: 0.0909,	steps: 2750/10160,	epoch: 4,	learning_rate: 7.77952755905512e-06
2024-11-24 22:12:29 [INFO]   loss: 0.0868,	steps: 2800/10160,	epoch: 4,	learning_rate: 7.72703412073491e-06
2024-11-24 22:12:53 [INFO]   loss: 0.3143,	steps: 2850/10160,	epoch: 4,	learning_rate: 7.674540682414698e-06
2024-11-24 22:13:16 [INFO]   loss: 0.1530,	steps: 2900/10160,	epoch: 4,	learning_rate: 7.622047244094489e-06
2024-11-24 22:13:40 [INFO]   loss: 0.0777,	steps: 2950/10160,	epoch: 4,	learning_rate: 7.569553805774279e-06
2024-11-24 22:14:03 [INFO]   loss: 0.2401,	steps: 3000/10160,	epoch: 4,	learning_rate: 7.5170603674540684e-06
2024-11-24 22:14:26 [INFO]   loss: 0.4403,	steps: 3050/10160,	epoch: 4,	learning_rate: 7.464566929133859e-06
2024-11-24 22:14:49 [INFO]   loss: 0.2754,	steps: 3100/10160,	epoch: 4,	learning_rate: 7.41207349081365e-06
2024-11-24 22:15:13 [INFO]   loss: 0.1172,	steps: 3150/10160,	epoch: 4,	learning_rate: 7.359580052493439e-06
2024-11-24 22:39:47 [INFO]   第4轮的训练 测试结果为：{'R@5': 0.437782004112248, 'R@10': 0.5954147236248625, 'RR@5': 0.7429074754901966, 'RR@10': 0.7509906045751639, 'nDCG@5': 0.5337741761108543, 'nDCG@10': 0.5806734624409129}
2024-11-24 22:39:59 [INFO]   loss: 0.0429,	steps: 3200/10160,	epoch: 5,	learning_rate: 7.307086614173229e-06
2024-11-24 22:40:22 [INFO]   loss: 0.1736,	steps: 3250/10160,	epoch: 5,	learning_rate: 7.254593175853018e-06
2024-11-24 22:40:46 [INFO]   loss: 0.3389,	steps: 3300/10160,	epoch: 5,	learning_rate: 7.202099737532809e-06
2024-11-24 22:41:10 [INFO]   loss: 0.1663,	steps: 3350/10160,	epoch: 5,	learning_rate: 7.1496062992125995e-06
2024-11-24 22:41:33 [INFO]   loss: 0.3902,	steps: 3400/10160,	epoch: 5,	learning_rate: 7.097112860892389e-06
2024-11-24 22:41:56 [INFO]   loss: 0.0873,	steps: 3450/10160,	epoch: 5,	learning_rate: 7.044619422572179e-06
2024-11-24 22:42:19 [INFO]   loss: 0.1854,	steps: 3500/10160,	epoch: 5,	learning_rate: 6.992125984251969e-06
2024-11-24 22:42:42 [INFO]   loss: 0.1615,	steps: 3550/10160,	epoch: 5,	learning_rate: 6.939632545931759e-06
2024-11-24 22:43:06 [INFO]   loss: 0.1444,	steps: 3600/10160,	epoch: 5,	learning_rate: 6.887139107611549e-06
2024-11-24 22:43:29 [INFO]   loss: 0.1529,	steps: 3650/10160,	epoch: 5,	learning_rate: 6.834645669291339e-06
2024-11-24 22:43:52 [INFO]   loss: 0.1283,	steps: 3700/10160,	epoch: 5,	learning_rate: 6.78215223097113e-06
2024-11-24 22:44:15 [INFO]   loss: 0.1806,	steps: 3750/10160,	epoch: 5,	learning_rate: 6.729658792650919e-06
2024-11-24 22:44:38 [INFO]   loss: 0.2157,	steps: 3800/10160,	epoch: 5,	learning_rate: 6.677165354330709e-06
2024-11-24 23:09:07 [INFO]   第5轮的训练 测试结果为：{'R@5': 0.4557265986837406, 'R@10': 0.6109474532537149, 'RR@5': 0.7678462009803929, 'RR@10': 0.7735440009337071, 'nDCG@5': 0.556981202832687, 'nDCG@10': 0.6031666766041449}
2024-11-24 23:09:26 [INFO]   loss: 0.1408,	steps: 3850/10160,	epoch: 6,	learning_rate: 6.624671916010499e-06
2024-11-24 23:09:49 [INFO]   loss: 0.0333,	steps: 3900/10160,	epoch: 6,	learning_rate: 6.57217847769029e-06
2024-11-24 23:10:12 [INFO]   loss: 0.0500,	steps: 3950/10160,	epoch: 6,	learning_rate: 6.51968503937008e-06
2024-11-24 23:10:35 [INFO]   loss: 0.0699,	steps: 4000/10160,	epoch: 6,	learning_rate: 6.467191601049869e-06
2024-11-24 23:10:58 [INFO]   loss: 0.1606,	steps: 4050/10160,	epoch: 6,	learning_rate: 6.414698162729659e-06
2024-11-24 23:11:21 [INFO]   loss: 0.3966,	steps: 4100/10160,	epoch: 6,	learning_rate: 6.362204724409449e-06
2024-11-24 23:11:45 [INFO]   loss: 0.2885,	steps: 4150/10160,	epoch: 6,	learning_rate: 6.3097112860892396e-06
2024-11-24 23:12:08 [INFO]   loss: 0.0194,	steps: 4200/10160,	epoch: 6,	learning_rate: 6.257217847769029e-06
2024-11-24 23:12:32 [INFO]   loss: 0.0632,	steps: 4250/10160,	epoch: 6,	learning_rate: 6.204724409448819e-06
2024-11-24 23:12:55 [INFO]   loss: 0.0550,	steps: 4300/10160,	epoch: 6,	learning_rate: 6.15223097112861e-06
2024-11-24 23:13:19 [INFO]   loss: 0.3665,	steps: 4350/10160,	epoch: 6,	learning_rate: 6.099737532808399e-06
2024-11-24 23:13:42 [INFO]   loss: 0.2214,	steps: 4400/10160,	epoch: 6,	learning_rate: 6.0472440944881895e-06
2024-11-24 23:38:28 [INFO]   第6轮的训练 测试结果为：{'R@5': 0.4152172611857605, 'R@10': 0.572839727438489, 'RR@5': 0.6660386029411774, 'RR@10': 0.6743402048319337, 'nDCG@5': 0.46567398352985506, 'nDCG@10': 0.5277415391656392}
2024-11-24 23:38:30 [INFO]   loss: 0.1164,	steps: 4450/10160,	epoch: 7,	learning_rate: 5.994750656167979e-06
2024-11-24 23:38:53 [INFO]   loss: 0.0900,	steps: 4500/10160,	epoch: 7,	learning_rate: 5.94225721784777e-06
2024-11-24 23:39:17 [INFO]   loss: 0.2995,	steps: 4550/10160,	epoch: 7,	learning_rate: 5.88976377952756e-06
2024-11-24 23:39:40 [INFO]   loss: 0.1157,	steps: 4600/10160,	epoch: 7,	learning_rate: 5.837270341207349e-06
2024-11-24 23:40:03 [INFO]   loss: 0.0399,	steps: 4650/10160,	epoch: 7,	learning_rate: 5.7847769028871395e-06
2024-11-24 23:40:27 [INFO]   loss: 0.0953,	steps: 4700/10160,	epoch: 7,	learning_rate: 5.7322834645669305e-06
2024-11-24 23:40:50 [INFO]   loss: 0.0641,	steps: 4750/10160,	epoch: 7,	learning_rate: 5.67979002624672e-06
2024-11-24 23:41:13 [INFO]   loss: 0.0561,	steps: 4800/10160,	epoch: 7,	learning_rate: 5.62729658792651e-06
2024-11-24 23:41:36 [INFO]   loss: 0.1672,	steps: 4850/10160,	epoch: 7,	learning_rate: 5.574803149606299e-06
2024-11-24 23:42:00 [INFO]   loss: 0.1010,	steps: 4900/10160,	epoch: 7,	learning_rate: 5.52230971128609e-06
2024-11-24 23:42:23 [INFO]   loss: 0.0954,	steps: 4950/10160,	epoch: 7,	learning_rate: 5.46981627296588e-06
2024-11-24 23:42:46 [INFO]   loss: 0.0886,	steps: 5000/10160,	epoch: 7,	learning_rate: 5.41732283464567e-06
2024-11-24 23:43:09 [INFO]   loss: 0.1743,	steps: 5050/10160,	epoch: 7,	learning_rate: 5.364829396325459e-06
2024-11-25 00:07:46 [INFO]   第7轮的训练 测试结果为：{'R@5': 0.47183339841235905, 'R@10': 0.6406231060982165, 'RR@5': 0.7908854166666669, 'RR@10': 0.7973294526143792, 'nDCG@5': 0.5805603987433645, 'nDCG@10': 0.629106785196756}
2024-11-25 00:07:49 [INFO]   ------------------------------------------------
2024-11-25 00:07:49 [INFO]   第 7 轮已经训练完成  模型保存在 /mnt/workspace/clir/myself/output/2024-11-24/best_model
2024-11-25 00:07:49 [INFO]   ------------------------------------------------
2024-11-25 00:07:59 [INFO]   loss: 0.0927,	steps: 5100/10160,	epoch: 8,	learning_rate: 5.31233595800525e-06
2024-11-25 00:08:22 [INFO]   loss: 0.1137,	steps: 5150/10160,	epoch: 8,	learning_rate: 5.25984251968504e-06
2024-11-25 00:08:46 [INFO]   loss: 0.0492,	steps: 5200/10160,	epoch: 8,	learning_rate: 5.2073490813648295e-06
2024-11-25 00:09:09 [INFO]   loss: 0.1071,	steps: 5250/10160,	epoch: 8,	learning_rate: 5.15485564304462e-06
2024-11-25 00:09:32 [INFO]   loss: 0.1315,	steps: 5300/10160,	epoch: 8,	learning_rate: 5.102362204724411e-06
2024-11-25 00:09:55 [INFO]   loss: 0.1558,	steps: 5350/10160,	epoch: 8,	learning_rate: 5.0498687664042e-06
2024-11-25 00:10:18 [INFO]   loss: 0.1288,	steps: 5400/10160,	epoch: 8,	learning_rate: 4.99737532808399e-06
2024-11-25 00:10:42 [INFO]   loss: 0.0658,	steps: 5450/10160,	epoch: 8,	learning_rate: 4.94488188976378e-06
2024-11-25 00:11:04 [INFO]   loss: 0.1717,	steps: 5500/10160,	epoch: 8,	learning_rate: 4.89238845144357e-06
2024-11-25 00:11:28 [INFO]   loss: 0.2266,	steps: 5550/10160,	epoch: 8,	learning_rate: 4.83989501312336e-06
2024-11-25 00:11:52 [INFO]   loss: 0.2010,	steps: 5600/10160,	epoch: 8,	learning_rate: 4.78740157480315e-06
2024-11-25 00:12:15 [INFO]   loss: 0.1208,	steps: 5650/10160,	epoch: 8,	learning_rate: 4.73490813648294e-06
2024-11-25 00:12:39 [INFO]   loss: 0.2697,	steps: 5700/10160,	epoch: 8,	learning_rate: 4.68241469816273e-06
2024-11-25 00:37:08 [INFO]   第8轮的训练 测试结果为：{'R@5': 0.501856160099687, 'R@10': 0.6705853222654515, 'RR@5': 0.8320159313725497, 'RR@10': 0.836257002801121, 'nDCG@5': 0.6185022370085325, 'nDCG@10': 0.6664172168194276}
2024-11-25 00:37:11 [INFO]   ------------------------------------------------
2024-11-25 00:37:11 [INFO]   第 8 轮已经训练完成  模型保存在 /mnt/workspace/clir/myself/output/2024-11-24/best_model
2024-11-25 00:37:11 [INFO]   ------------------------------------------------
2024-11-25 00:37:27 [INFO]   loss: 0.1414,	steps: 5750/10160,	epoch: 9,	learning_rate: 4.6299212598425204e-06
2024-11-25 00:37:50 [INFO]   loss: 0.0261,	steps: 5800/10160,	epoch: 9,	learning_rate: 4.57742782152231e-06
2024-11-25 00:38:14 [INFO]   loss: 0.1855,	steps: 5850/10160,	epoch: 9,	learning_rate: 4.5249343832021e-06
2024-11-25 00:38:37 [INFO]   loss: 0.3372,	steps: 5900/10160,	epoch: 9,	learning_rate: 4.47244094488189e-06
2024-11-25 00:39:00 [INFO]   loss: 0.0349,	steps: 5950/10160,	epoch: 9,	learning_rate: 4.41994750656168e-06
2024-11-25 00:39:23 [INFO]   loss: 0.2201,	steps: 6000/10160,	epoch: 9,	learning_rate: 4.36745406824147e-06
2024-11-25 00:39:46 [INFO]   loss: 0.1388,	steps: 6050/10160,	epoch: 9,	learning_rate: 4.3149606299212606e-06
2024-11-25 00:40:09 [INFO]   loss: 0.3520,	steps: 6100/10160,	epoch: 9,	learning_rate: 4.26246719160105e-06
2024-11-25 00:40:33 [INFO]   loss: 0.0397,	steps: 6150/10160,	epoch: 9,	learning_rate: 4.209973753280841e-06
2024-11-25 00:40:56 [INFO]   loss: 0.0107,	steps: 6200/10160,	epoch: 9,	learning_rate: 4.15748031496063e-06
2024-11-25 00:41:19 [INFO]   loss: 0.0152,	steps: 6250/10160,	epoch: 9,	learning_rate: 4.10498687664042e-06
2024-11-25 00:41:42 [INFO]   loss: 0.2083,	steps: 6300/10160,	epoch: 9,	learning_rate: 4.0524934383202105e-06
2024-11-25 00:42:06 [INFO]   loss: 0.1974,	steps: 6350/10160,	epoch: 9,	learning_rate: 4.000000000000001e-06
2024-11-25 01:06:29 [INFO]   第9轮的训练 测试结果为：{'R@5': 0.5039692825038641, 'R@10': 0.6726468913579968, 'RR@5': 0.8271752450980399, 'RR@10': 0.8316150939542487, 'nDCG@5': 0.6128249596099635, 'nDCG@10': 0.6635506103450659}
2024-11-25 01:06:52 [INFO]   loss: 0.1354,	steps: 6400/10160,	epoch: 10,	learning_rate: 3.94750656167979e-06
2024-11-25 01:07:15 [INFO]   loss: 0.1319,	steps: 6450/10160,	epoch: 10,	learning_rate: 3.895013123359581e-06
2024-11-25 01:07:38 [INFO]   loss: 0.0666,	steps: 6500/10160,	epoch: 10,	learning_rate: 3.84251968503937e-06
2024-11-25 01:08:01 [INFO]   loss: 0.0389,	steps: 6550/10160,	epoch: 10,	learning_rate: 3.7900262467191605e-06
2024-11-25 01:08:23 [INFO]   loss: 0.0668,	steps: 6600/10160,	epoch: 10,	learning_rate: 3.73753280839895e-06
2024-11-25 01:08:47 [INFO]   loss: 0.3015,	steps: 6650/10160,	epoch: 10,	learning_rate: 3.6850393700787408e-06
2024-11-25 01:09:10 [INFO]   loss: 0.1593,	steps: 6700/10160,	epoch: 10,	learning_rate: 3.6325459317585305e-06
2024-11-25 01:09:33 [INFO]   loss: 0.0534,	steps: 6750/10160,	epoch: 10,	learning_rate: 3.5800524934383207e-06
2024-11-25 01:09:57 [INFO]   loss: 0.0912,	steps: 6800/10160,	epoch: 10,	learning_rate: 3.5275590551181104e-06
2024-11-25 01:10:20 [INFO]   loss: 0.2028,	steps: 6850/10160,	epoch: 10,	learning_rate: 3.4750656167979006e-06
2024-11-25 01:10:43 [INFO]   loss: 0.0497,	steps: 6900/10160,	epoch: 10,	learning_rate: 3.4225721784776907e-06
2024-11-25 01:11:06 [INFO]   loss: 0.0934,	steps: 6950/10160,	epoch: 10,	learning_rate: 3.370078740157481e-06
2024-11-25 01:35:46 [INFO]   第10轮的训练 测试结果为：{'R@5': 0.513929613899515, 'R@10': 0.6802976396609612, 'RR@5': 0.835677083333334, 'RR@10': 0.8397908642623721, 'nDCG@5': 0.6260490364722899, 'nDCG@10': 0.6743174679820241}
2024-11-25 01:35:49 [INFO]   ------------------------------------------------
2024-11-25 01:35:49 [INFO]   第 10 轮已经训练完成  模型保存在 /mnt/workspace/clir/myself/output/2024-11-24/best_model
2024-11-25 01:35:49 [INFO]   ------------------------------------------------
2024-11-25 01:35:56 [INFO]   loss: 0.1028,	steps: 7000/10160,	epoch: 11,	learning_rate: 3.3175853018372706e-06
2024-11-25 01:36:19 [INFO]   loss: 0.1619,	steps: 7050/10160,	epoch: 11,	learning_rate: 3.2650918635170608e-06
2024-11-25 01:36:41 [INFO]   loss: 0.0475,	steps: 7100/10160,	epoch: 11,	learning_rate: 3.2125984251968505e-06
2024-11-25 01:37:04 [INFO]   loss: 0.0717,	steps: 7150/10160,	epoch: 11,	learning_rate: 3.160104986876641e-06
2024-11-25 01:37:28 [INFO]   loss: 0.0781,	steps: 7200/10160,	epoch: 11,	learning_rate: 3.107611548556431e-06
2024-11-25 01:37:51 [INFO]   loss: 0.0475,	steps: 7250/10160,	epoch: 11,	learning_rate: 3.055118110236221e-06
2024-11-25 01:38:14 [INFO]   loss: 0.0347,	steps: 7300/10160,	epoch: 11,	learning_rate: 3.0026246719160107e-06
2024-11-25 01:38:37 [INFO]   loss: 0.2972,	steps: 7350/10160,	epoch: 11,	learning_rate: 2.950131233595801e-06
2024-11-25 01:39:01 [INFO]   loss: 0.0293,	steps: 7400/10160,	epoch: 11,	learning_rate: 2.8976377952755906e-06
2024-11-25 01:39:24 [INFO]   loss: 0.3069,	steps: 7450/10160,	epoch: 11,	learning_rate: 2.8451443569553812e-06
2024-11-25 01:39:47 [INFO]   loss: 0.0398,	steps: 7500/10160,	epoch: 11,	learning_rate: 2.792650918635171e-06
2024-11-25 01:40:11 [INFO]   loss: 0.0852,	steps: 7550/10160,	epoch: 11,	learning_rate: 2.740157480314961e-06
2024-11-25 01:40:34 [INFO]   loss: 0.1012,	steps: 7600/10160,	epoch: 11,	learning_rate: 2.687664041994751e-06
2024-11-25 02:05:07 [INFO]   第11轮的训练 测试结果为：{'R@5': 0.5187656460156957, 'R@10': 0.6835059607562077, 'RR@5': 0.8435508578431379, 'RR@10': 0.8477474323062563, 'nDCG@5': 0.6356756480325145, 'nDCG@10': 0.6813072566824507}
2024-11-25 02:05:10 [INFO]   ------------------------------------------------
2024-11-25 02:05:10 [INFO]   第 11 轮已经训练完成  模型保存在 /mnt/workspace/clir/myself/output/2024-11-24/best_model
2024-11-25 02:05:10 [INFO]   ------------------------------------------------
2024-11-25 02:05:24 [INFO]   loss: 0.1423,	steps: 7650/10160,	epoch: 12,	learning_rate: 2.635170603674541e-06
2024-11-25 02:05:47 [INFO]   loss: 0.2063,	steps: 7700/10160,	epoch: 12,	learning_rate: 2.5826771653543307e-06
2024-11-25 02:06:10 [INFO]   loss: 0.0537,	steps: 7750/10160,	epoch: 12,	learning_rate: 2.5301837270341213e-06
2024-11-25 02:06:33 [INFO]   loss: 0.0375,	steps: 7800/10160,	epoch: 12,	learning_rate: 2.477690288713911e-06
2024-11-25 02:06:56 [INFO]   loss: 0.2175,	steps: 7850/10160,	epoch: 12,	learning_rate: 2.425196850393701e-06
2024-11-25 02:07:20 [INFO]   loss: 0.1614,	steps: 7900/10160,	epoch: 12,	learning_rate: 2.372703412073491e-06
2024-11-25 02:07:42 [INFO]   loss: 0.0418,	steps: 7950/10160,	epoch: 12,	learning_rate: 2.320209973753281e-06
2024-11-25 02:08:06 [INFO]   loss: 0.1186,	steps: 8000/10160,	epoch: 12,	learning_rate: 2.267716535433071e-06
2024-11-25 02:08:29 [INFO]   loss: 0.0039,	steps: 8050/10160,	epoch: 12,	learning_rate: 2.215223097112861e-06
2024-11-25 02:08:52 [INFO]   loss: 0.1648,	steps: 8100/10160,	epoch: 12,	learning_rate: 2.162729658792651e-06
2024-11-25 02:09:17 [INFO]   loss: 0.0168,	steps: 8150/10160,	epoch: 12,	learning_rate: 2.110236220472441e-06
2024-11-25 02:09:40 [INFO]   loss: 0.0149,	steps: 8200/10160,	epoch: 12,	learning_rate: 2.057742782152231e-06
2024-11-25 02:10:03 [INFO]   loss: 0.0096,	steps: 8250/10160,	epoch: 12,	learning_rate: 2.0052493438320212e-06
2024-11-25 02:34:30 [INFO]   第12轮的训练 测试结果为：{'R@5': 0.5230519218881562, 'R@10': 0.6824549557673231, 'RR@5': 0.8312346813725495, 'RR@10': 0.835322566526611, 'nDCG@5': 0.6311636588228247, 'nDCG@10': 0.6756912713027392}
2024-11-25 02:34:51 [INFO]   loss: 0.1737,	steps: 8300/10160,	epoch: 13,	learning_rate: 1.952755905511811e-06
2024-11-25 02:35:14 [INFO]   loss: 0.1448,	steps: 8350/10160,	epoch: 13,	learning_rate: 1.9002624671916011e-06
2024-11-25 02:35:37 [INFO]   loss: 0.0699,	steps: 8400/10160,	epoch: 13,	learning_rate: 1.8477690288713913e-06
2024-11-25 02:36:00 [INFO]   loss: 0.0257,	steps: 8450/10160,	epoch: 13,	learning_rate: 1.7952755905511812e-06
2024-11-25 02:36:23 [INFO]   loss: 0.0932,	steps: 8500/10160,	epoch: 13,	learning_rate: 1.7427821522309712e-06
2024-11-25 02:36:46 [INFO]   loss: 0.0848,	steps: 8550/10160,	epoch: 13,	learning_rate: 1.6902887139107613e-06
2024-11-25 02:37:10 [INFO]   loss: 0.1824,	steps: 8600/10160,	epoch: 13,	learning_rate: 1.6377952755905513e-06
2024-11-25 02:37:33 [INFO]   loss: 0.1902,	steps: 8650/10160,	epoch: 13,	learning_rate: 1.5853018372703412e-06
2024-11-25 02:37:56 [INFO]   loss: 0.0685,	steps: 8700/10160,	epoch: 13,	learning_rate: 1.5328083989501314e-06
2024-11-25 02:38:20 [INFO]   loss: 0.0333,	steps: 8750/10160,	epoch: 13,	learning_rate: 1.4803149606299213e-06
2024-11-25 02:38:44 [INFO]   loss: 0.0499,	steps: 8800/10160,	epoch: 13,	learning_rate: 1.4278215223097113e-06
2024-11-25 02:39:07 [INFO]   loss: 0.0441,	steps: 8850/10160,	epoch: 13,	learning_rate: 1.3753280839895015e-06
2024-11-25 03:03:51 [INFO]   第13轮的训练 测试结果为：{'R@5': 0.5259650116472318, 'R@10': 0.6873435477185552, 'RR@5': 0.8427696078431378, 'RR@10': 0.846447172619048, 'nDCG@5': 0.6398980987971443, 'nDCG@10': 0.6849386406379265}
2024-11-25 03:03:54 [INFO]   ------------------------------------------------
2024-11-25 03:03:54 [INFO]   第 13 轮已经训练完成  模型保存在 /mnt/workspace/clir/myself/output/2024-11-24/best_model
2024-11-25 03:03:54 [INFO]   ------------------------------------------------
2024-11-25 03:03:58 [INFO]   loss: 0.0878,	steps: 8900/10160,	epoch: 14,	learning_rate: 1.3228346456692914e-06
2024-11-25 03:04:22 [INFO]   loss: 0.1326,	steps: 8950/10160,	epoch: 14,	learning_rate: 1.2703412073490814e-06
2024-11-25 03:04:45 [INFO]   loss: 0.1013,	steps: 9000/10160,	epoch: 14,	learning_rate: 1.2178477690288715e-06
2024-11-25 03:05:08 [INFO]   loss: 0.1504,	steps: 9050/10160,	epoch: 14,	learning_rate: 1.1653543307086615e-06
2024-11-25 03:05:31 [INFO]   loss: 0.0246,	steps: 9100/10160,	epoch: 14,	learning_rate: 1.1128608923884516e-06
2024-11-25 03:05:55 [INFO]   loss: 0.0472,	steps: 9150/10160,	epoch: 14,	learning_rate: 1.0603674540682416e-06
2024-11-25 03:06:18 [INFO]   loss: 0.1954,	steps: 9200/10160,	epoch: 14,	learning_rate: 1.0078740157480315e-06
2024-11-25 03:06:41 [INFO]   loss: 0.0503,	steps: 9250/10160,	epoch: 14,	learning_rate: 9.553805774278217e-07
2024-11-25 03:07:04 [INFO]   loss: 0.0138,	steps: 9300/10160,	epoch: 14,	learning_rate: 9.028871391076116e-07
2024-11-25 03:07:27 [INFO]   loss: 0.0989,	steps: 9350/10160,	epoch: 14,	learning_rate: 8.503937007874017e-07
2024-11-25 03:07:50 [INFO]   loss: 0.0175,	steps: 9400/10160,	epoch: 14,	learning_rate: 7.979002624671916e-07
2024-11-25 03:08:14 [INFO]   loss: 0.1000,	steps: 9450/10160,	epoch: 14,	learning_rate: 7.454068241469817e-07
2024-11-25 03:08:37 [INFO]   loss: 0.0604,	steps: 9500/10160,	epoch: 14,	learning_rate: 6.929133858267717e-07
2024-11-25 03:33:12 [INFO]   第14轮的训练 测试结果为：{'R@5': 0.5189626718760769, 'R@10': 0.6850706205252454, 'RR@5': 0.8359528186274517, 'RR@10': 0.8396318423202618, 'nDCG@5': 0.6327289647896641, 'nDCG@10': 0.6812118699818934}
2024-11-25 03:33:23 [INFO]   loss: 0.0390,	steps: 9550/10160,	epoch: 15,	learning_rate: 6.404199475065617e-07
2024-11-25 03:33:47 [INFO]   loss: 0.1842,	steps: 9600/10160,	epoch: 15,	learning_rate: 5.879265091863517e-07
2024-11-25 03:34:10 [INFO]   loss: 0.0558,	steps: 9650/10160,	epoch: 15,	learning_rate: 5.354330708661418e-07
2024-11-25 03:34:32 [INFO]   loss: 0.0859,	steps: 9700/10160,	epoch: 15,	learning_rate: 4.829396325459318e-07
2024-11-25 03:34:55 [INFO]   loss: 0.3032,	steps: 9750/10160,	epoch: 15,	learning_rate: 4.304461942257218e-07
2024-11-25 03:35:19 [INFO]   loss: 0.0465,	steps: 9800/10160,	epoch: 15,	learning_rate: 3.7795275590551184e-07
2024-11-25 03:35:42 [INFO]   loss: 0.1065,	steps: 9850/10160,	epoch: 15,	learning_rate: 3.2545931758530185e-07
2024-11-25 03:36:05 [INFO]   loss: 0.2647,	steps: 9900/10160,	epoch: 15,	learning_rate: 2.729658792650919e-07
2024-11-25 03:36:28 [INFO]   loss: 0.0341,	steps: 9950/10160,	epoch: 15,	learning_rate: 2.204724409448819e-07
2024-11-25 03:36:51 [INFO]   loss: 0.0445,	steps: 10000/10160,	epoch: 15,	learning_rate: 1.6797900262467193e-07
2024-11-25 03:37:14 [INFO]   loss: 0.0762,	steps: 10050/10160,	epoch: 15,	learning_rate: 1.1548556430446196e-07
2024-11-25 03:37:38 [INFO]   loss: 0.1390,	steps: 10100/10160,	epoch: 15,	learning_rate: 6.299212598425197e-08
2024-11-25 03:38:01 [INFO]   loss: 0.0103,	steps: 10150/10160,	epoch: 15,	learning_rate: 1.0498687664041996e-08
2024-11-25 04:02:27 [INFO]   第15轮的训练 测试结果为：{'R@5': 0.521819719334998, 'R@10': 0.6837624278543398, 'RR@5': 0.8392156862745104, 'RR@10': 0.8425547823295989, 'nDCG@5': 0.6363290117470372, 'nDCG@10': 0.6829856543889095}
2024-11-25 04:02:27 [INFO]   ------------------------------------------------
2024-11-25 04:02:27 [INFO]   最佳评测指标为: {'R@5': 0.5259650116472318, 'R@10': 0.6873435477185552, 'RR@5': 0.8427696078431378, 'RR@10': 0.846447172619048, 'nDCG@5': 0.6398980987971443, 'nDCG@10': 0.6849386406379265}
2024-11-25 04:02:27 [INFO]   ------------------------------------------------
2024-11-25 04:02:27 [INFO]   ------------------------------------------------
2024-11-25 04:02:27 [INFO]   所有epoch的平均评测指标为: {'R@5': 0.4806553792706202, 'R@10': 0.6420979037437974, 'RR@5': 0.7829111136642163, 'RR@10': 0.7885774329262959, 'nDCG@5': 0.5793193611848562, 'nDCG@10': 0.6284474658982769}
2024-11-25 04:02:27 [INFO]   ------------------------------------------------

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = Path.home() / 'Desktop' / 'clir' / 'data' / 'wikidata' / 'base_data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- 过滤 query 的 QID ---------------------\n",
    "QID_search_results_file = str(HOME_DIR / 'base_test1_qid.csv')\n",
    "QID_filtered_search_results_file = str(HOME_DIR / 'base_test1_qid_filtered.csv')\n",
    "\n",
    "def filter_qid(original_file: str, filtered_file: str):\n",
    "\n",
    "    QID_df = pd.read_csv(original_file, encoding='utf-8')\n",
    "\n",
    "    # columns_to_keep = ['query', 'search_term', 'id', 'label', 'description']\n",
    "    columns_to_keep = ['query_id', 'query', 'qid']\n",
    "\n",
    "    # 只取 columns_to_keep 列数据，然后去除 id 列 为NaN的行数据\n",
    "    QID_filtered_df = QID_df[columns_to_keep].dropna(subset=['qid'])\n",
    "    # 去除重复项\n",
    "    QID_filtered_df.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "    # 保存文件\n",
    "    QID_filtered_df.to_csv(filtered_file, index=False, encoding='utf-8')\n",
    "\n",
    "filter_qid(QID_search_results_file, QID_filtered_search_results_file)\n",
    "\n",
    "# QID_df = pd.read_csv(QID_search_results_file, encoding='utf-8')\n",
    "\n",
    "# columns_to_keep = ['query_id', 'query', 'qid']\n",
    "# QID_filtered_df = QID_df[columns_to_keep]\n",
    "\n",
    "# ddd = str(HOME_DIR / 'base_test1_qid.csv')\n",
    "\n",
    "# QID_filtered_df.to_csv(ddd, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- 删除 实体、属性英文信息为空的行数据 ---------------------\n",
    "def filter_item_info(original_file: str, filtered_file: str):\n",
    "\n",
    "    item_info_df = pd.read_csv(original_file, encoding='utf-8')\n",
    "    # 删除'label_en', 'description_en' 为空的行数据\n",
    "    item_info_df = item_info_df.dropna(subset=['label_en', 'description_en'], how='any')\n",
    "\n",
    "    # 删除重复数据\n",
    "    item_info_df.drop_duplicates(inplace=True)\n",
    "\n",
    "    item_info_df.to_csv(filtered_file, index=False, encoding='utf-8')\n",
    "\n",
    "item_info_file = str(HOME_DIR / 'base_train_adj_item_info.csv')\n",
    "item_filtered_info_file = str(HOME_DIR / 'base_train_adj_item_filtered_info.csv')\n",
    "\n",
    "filter_item_info(item_info_file, item_filtered_info_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- 过滤三元组 （实体-关系-实体) ---------------------\n",
    "def filter_triplet_id(original_file: str, filtered_file: str):\n",
    "    # 读取 CSV 文件\n",
    "    triplet_id_df = pd.read_csv(original_file, encoding='utf-8')\n",
    "\n",
    "    # 删除含有任何 NaN 值的行\n",
    "    triplet_id_df = triplet_id_df.dropna()\n",
    "\n",
    "    # 确保 AdjItem 列中的值是字符串类型，并且填充 NaN 值\n",
    "    triplet_id_df['adj_item_qid'] = triplet_id_df['adj_item_qid'].astype(str)\n",
    "\n",
    "    # 使用正则表达式过滤符合条件的行 匹配以 \"Q\" 开头后跟数字的字符串\n",
    "    # na=False 确保 NaN 值不会引起错误。\n",
    "    triplet_id_filtered_df = triplet_id_df[triplet_id_df['adj_item_qid'].str.match(r'^Q\\d+$', na=False)]\n",
    "\n",
    "    # 删除 重复行\n",
    "    triplet_id_filtered_df = triplet_id_filtered_df.drop_duplicates(keep='first')\n",
    "\n",
    "    # 将结果保存到 CSV 文件\n",
    "    triplet_id_filtered_df.to_csv(filtered_file, index=False, encoding='utf-8')\n",
    "\n",
    "triplet_id_file = str(HOME_DIR / 'triplet_id_595.csv')\n",
    "triplet_id_filtered_file = str(HOME_DIR / 'triplet_id_595_filtered.csv')\n",
    "\n",
    "filter_triplet_id(triplet_id_file, triplet_id_filtered_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- 获取 triplet_id 片段 ---------------------\n",
    "# 对于每一个item的每一个属性对应的最多 n个 adj_item\n",
    "def get_triplet_id_fragment(original_file: str, filtered_file: str, n: int):\n",
    "    # 读取原始文件\n",
    "    triplet_id_df = pd.read_csv(original_file, encoding='utf-8')\n",
    "\n",
    "    # 设置随机种子\n",
    "    seed = 33\n",
    "\n",
    "    # 创建一个空的列表来存储结果\n",
    "    result_list = []\n",
    "\n",
    "    # 对数据进行分组\n",
    "    grouped = triplet_id_df.groupby(['item_qid', 'property_qid'])\n",
    "\n",
    "    # 遍历每个分组\n",
    "    for (item_qid, property_qid), group in grouped:\n",
    "        # 如果组的大小小于或等于 n，直接添加整个组\n",
    "        if len(group) <= n:\n",
    "            result_list.append(group)\n",
    "        else:\n",
    "            # 否则，随机选择 n 个样本\n",
    "            sampled = group.sample(n, random_state=seed)\n",
    "            result_list.append(sampled)\n",
    "\n",
    "    # 将结果列表连接成一个 DataFrame\n",
    "    result_df = pd.concat(result_list, ignore_index=True)\n",
    "\n",
    "    # 将结果保存到新的 CSV 文件中\n",
    "    result_df.to_csv(filtered_file, index=False, encoding='utf-8')\n",
    "\n",
    "triplet_id_file = str(HOME_DIR / 'triplet_id_filtered.csv')\n",
    "triplet_id_fragment_file = str(HOME_DIR / 'triplet_id_fragment.csv')\n",
    "\n",
    "get_triplet_id_fragment(triplet_id_file, triplet_id_fragment_file, n=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不存在空值\n"
     ]
    }
   ],
   "source": [
    "# 使用翻译引擎填充完缺失值后 检查是否还存在 空值 如果还存在空值 数量不多的情况下 手动 翻译 填充\n",
    "# 读取文件\n",
    "item_info_filled_file = str(HOME_DIR / 'base_train_query_entity_filled_info.csv')\n",
    "item_info_filled_df = pd.read_csv(item_info_filled_file, encoding='utf-8')\n",
    "# 将存在空值的行的 index 转成列表\n",
    "empty_index_list=item_info_filled_df[item_info_filled_df.isnull().any(axis=1)].index.to_list()\n",
    "\n",
    "# \n",
    "if len(empty_index_list) == 0:\n",
    "    print(\"不存在空值\")\n",
    "else:\n",
    "    empty_qid_list = []\n",
    "    for index in empty_index_list:\n",
    "        item_qid = item_info_filled_df.loc[index]['item_qid']\n",
    "        empty_qid_list.append(item_qid)\n",
    "    print(\"存在空值的实体的 qid 列表：\")\n",
    "    print(f\"{empty_qid_list}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yandex 翻译 调用测试\n",
    "# import requests\n",
    "\n",
    "# text = \"Yu Fei\"\n",
    "\n",
    "# url = f\"https://translate.yandex.com/?source_lang=en&target_lang=kk&text={text}\" \n",
    "\n",
    "# response = requests.get(url)\n",
    "\n",
    "# print(response.json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并完成，输出文件: C:\\Users\\bajiuqier\\Desktop\\clir\\data\\wikidata\\base_train_adj_item_info\\base_train_adj_item_info.csv\n"
     ]
    }
   ],
   "source": [
    "from utils import merge_csv_files\n",
    "\n",
    "ADJ_ITEM_INFO_HOME_DIR = Path.home() / 'Desktop' / 'clir' / 'data' / 'wikidata' / 'base_train_adj_item_info'\n",
    "\n",
    "# 合并所有的query-entity信息\n",
    "pattern = r'base_train_adj_item_info_\\d+\\.csv'\n",
    "\n",
    "folder_path = str(ADJ_ITEM_INFO_HOME_DIR)\n",
    "output_file = str(ADJ_ITEM_INFO_HOME_DIR / 'base_train_adj_item_info.csv')\n",
    "\n",
    "merge_csv_files(folder_path=folder_path, output_file=output_file, pattern=pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
